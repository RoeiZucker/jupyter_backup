{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ukbb_parser import create_dataset, create_ICD10_dataset, get_chrom_raw_marker_data, get_chrom_imputation_data\n",
    "from ukbb_parser.shared_utils.util import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "print(\"here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHENOTYPES = [\n",
    "    # The format is: ('field_name', field_id, 'field_type')\n",
    "    # field_name could be anything you like (this will determine the column name in the resulted dataframe)\n",
    "    # fiel_id is the ID of the UKBB field (e.g. http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=50)\n",
    "    # field_type could be any of:\n",
    "    # - 'continuous' (will take the maximum among all the existing records for each sample)\n",
    "    # - 'binary' (i.e. 0 or 1)\n",
    "    # - 'set' (will return a set with all the values found for each sample; note that this is dramatically slower to parse)\n",
    "    # - You can also specify a Python function that takes all the values (as a dataframe) and returns the final values (as\n",
    "    # a series with the same index).\n",
    "    ('height', 50, 'continuous'),\n",
    "    ('diastolic_blood_preasure', 4079, 'continuous'),\n",
    "    ('red_blood_cell_count', 30010, 'continuous'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021_06_22-19:03:30] Reading all dataset rows of 26 columns (for 8 fields)...\n"
     ]
    }
   ],
   "source": [
    "# Parses the specified phenotypes. It is recommended to look at all the documentation, and in particular at all the \n",
    "# optional arguments, of the create_dataset function. In particular you should double-check that you are really\n",
    "# interested in the behavior dictated by the default values of the arguments (especially those flags which determine\n",
    "# the filtration steps).\n",
    "eid, fields, covariates = create_dataset(PHENOTYPES, nrows = None)\n",
    "\n",
    "# As a result, we get back three dataframes/series, all with the same index (so you can think of them as three pieces of\n",
    "# the same table). Each row in the table represents one sample/individual.\n",
    "\n",
    "# eid is the UKBB phenotype ID of each sample in our project (which appears in the project-specific files).\n",
    "summarize(eid)\n",
    "\n",
    "# This dataframe contains all the fields that have been explicitly requested (described by the PHENOTYPES list).\n",
    "summarize(fields)\n",
    "\n",
    "# The covariates are variables that are always parsed and returned (unless stated otherwise in the parameters),\n",
    "# and should be accounted for if the fields are used as part of a genetic association study. These include:\n",
    "# - const: A constant 1, used as an intercept for regression/classification models.\n",
    "# - sex: 1 for males, 0 for females\n",
    "# - year_of_birth\n",
    "# - PC1-PC40: 40 principle components of PCA over the ~800K genetic markers.\n",
    "# - assessment centers (ACs) in which the samples have been recruited and processed.\n",
    "# - batches: One-hot-encoding of the batch in which the samples have been sequenced.\n",
    "summarize(covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The function create_ICD10_dataset is similar to create_dataset (with mostly overlapping arguments). The main difference\n",
    "# between the two functions is that create_ICD10_dataset also returns an ICD10_tree for the samples. The ICD10_tree is\n",
    "# yet another dataframe, with each row representing a node of the ICD-10 tree. The 'samples' column provides the set of\n",
    "# all sample indices associated with each ICD-10 code (these indices are simply the index of the other three dataframes). \n",
    "eid, ICD10_tree, additional_fields, covariates, _ = create_ICD10_dataset(PHENOTYPES, nrows = None)\n",
    "summarize(eid)\n",
    "summarize(ICD10_tree)\n",
    "summarize(additional_fields)\n",
    "summarize(covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples working with the phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: A graph showing diastolic blood preasure vs. red blood cell count\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(additional_fields['diastolic_blood_preasure'], additional_fields['red_blood_cell_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: A graph showing height distribution per sex\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot([additional_fields.loc[covariates['sex'] == 0, 'height'].dropna(), \\\n",
    "        additional_fields.loc[covariates['sex'] == 1, 'height'].dropna()])\n",
    "ax.set_xticklabels(['F', 'M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with genetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw markers (BED files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the genetic data for chr17.\n",
    "bim, fam, G = get_chrom_raw_marker_data('17')\n",
    "\n",
    "# 'bim' is a dataframe containing information about the variants.\n",
    "display(bim.head())\n",
    "print('%d total variants.' % len(bim))\n",
    "\n",
    "# 'fam' is a dataframe containing information about the samples (specifically, we need it to map the sample IDs).\n",
    "assert (fam['i'] == np.arange(len(fam))).all()\n",
    "summarize(fam)\n",
    "\n",
    "# G is the genotyping matrix (see usage below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to query the genotypes corresponding to samples in the phenotypic dataset we've parsed, we create a series\n",
    "# mapping each sample_index (i.e. the index shared by 'eid', 'additional_fields', 'covariates' etc.) to its correspondig \n",
    "# index within the G matrix. This is done by creating a series mapping between the 'iid' (= eid) to the 'i' columns in the\n",
    "# 'fam' dataframe. Note that the column 'i' provides the index within G of each sample.\n",
    "genotyping_index = eid.map(fam.astype({'iid': int}).set_index('iid')['i'])\n",
    "summarize(genotyping_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# As a simple example, we will run association tests for each of the the variants in the gonomic locus\n",
    "# chr17:59,500,000-59,520,000 against the height phenotype.\n",
    "relevant_variants = bim[bim['pos'].between(59500000, 59520000)].copy()\n",
    "\n",
    "pval_results = []\n",
    "\n",
    "for i, (_, variant) in enumerate(relevant_variants.iterrows()):\n",
    "    \n",
    "    print('Variant %d/%d' % (i + 1, len(relevant_variants)), end = '\\r')\n",
    "    \n",
    "    # variant['i'] gives the index of the variant, so taking this row in the G matrix will give the genotypes of all the\n",
    "    # UKBB samples for this variant. The values in the G matrix indicate the genotype of each individual for each variant.\n",
    "    # These values can be 0 (homozygous reference, i.e. no copies of the alternative allele), 1 (heterozygous, i.e. one\n",
    "    # copy of the alternative allele) or 2 (homozygous alternative, i.e. two copies of the alternative allele).\n",
    "    variant_genotypes = G[variant['i'], :].compute()\n",
    "    # We use the genotyping_index to retrieve only the relevant samples from the loaded genotypes (and in the right order),\n",
    "    # so we end up with a vector of genotypes aligned to our dataset.\n",
    "    sample_variant_genotypes = variant_genotypes[genotyping_index.values]\n",
    "    sample_variant_genotypes = pd.Series(sample_variant_genotypes, index = eid.index).rename('genotype')\n",
    "    \n",
    "    # We construct the relevant dataset for this variant. The exogenous variables (X) will be all the covariates, along\n",
    "    # with the genotypes (the variable we are really interested in) and the endogenous variable (y) will be the height.\n",
    "    mask = pd.notnull(sample_variant_genotypes) & pd.notnull(additional_fields['height'])\n",
    "    y = additional_fields.loc[mask, 'height']\n",
    "    X = pd.concat([covariates, sample_variant_genotypes], axis = 1).loc[mask]\n",
    "    \n",
    "    # We train a simple linear-regression model (OLS) to calculate a p-value for this variant's genotypes (as a variable\n",
    "    # in the OLS, after accounting for all other covariates).\n",
    "    model = sm.OLS(y, X)\n",
    "    variant_results = model.fit()\n",
    "    pval = variant_results.pvalues['genotype']\n",
    "    pval_results.append(pval)\n",
    "\n",
    "# We finalize and display the results (the p-value derived for any of the variants).\n",
    "relevant_variants['height_pval'] = pval_results\n",
    "display(relevant_variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation genetic data (BGEN files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the imputation data for chr16.\n",
    "chrom_imputation_reader = get_chrom_imputation_data('16')\n",
    "\n",
    "# All the imputed variants on the chromosome can be accessed through this dataframe. \n",
    "display(chrom_imputation_reader.variants.head())\n",
    "\n",
    "print('%d total variants.' % chrom_imputation_reader.n_variants)\n",
    "print('%d samples with imputed variants on this chromosome.' % chrom_imputation_reader.n_samples)\n",
    "\n",
    "# Provides the eid corresponding to each sample in the imputation reader.\n",
    "summarize(chrom_imputation_reader.sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to query the imputed genotypes corresponding to samples in the phenotypic dataset we've parsed, we create a\n",
    "# series mapping each sample_index (i.e. the index shared by 'eid', 'additional_fields', 'covariates' etc.) to its\n",
    "# correspondig index within chrom_imputation_reader. This is done by creating a series mapping between the 'sample_ids'\n",
    "# (= eid) to the index.\n",
    "imputation_index = eid.map(chrom_imputation_reader.sample_ids.reset_index().set_index('eid')['index'])\n",
    "imputation_mask = pd.notnull(imputation_index)\n",
    "print('%d of the %d dataset samples have imputated variants on this chromosome.' % (imputation_mask.sum(), \\\n",
    "        len(imputation_mask)))\n",
    "imputation_index = imputation_index[imputation_mask].astype(int)\n",
    "summarize(imputation_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "\n",
    "'''\n",
    "As a simple example, we consider the association between the variant rs9930506 in the FTO gene on chr16 to obesity (ICD-10\n",
    "code E66). According to SNPedia, there should be an association between them (https://www.snpedia.com/index.php/Rs9930506).\n",
    "'''\n",
    "\n",
    "# We query the record of the variant we look for (given by rsid).\n",
    "(_, variant_record), = chrom_imputation_reader.variants[chrom_imputation_reader.variants['rsid'] == 'rs9930506'].iterrows()\n",
    "display(variant_record)\n",
    "\n",
    "# We read the genotyping for the variant by providing the variant index (which is the name of the relevant row in the\n",
    "# chrom_imputation_reader.variants dataframe).\n",
    "variant_genotyping_probs = chrom_imputation_reader.read_variant_probs(variant_record.name)\n",
    "# We use imputation_index to retrieve only the relevant samples from the loaded genotypes (and in the right order),\n",
    "# so we end up with a vector of genotypes aligned to our dataset.\n",
    "sample_variant_genotyping_probs = variant_genotyping_probs[imputation_index.values, :]\n",
    "# The variant's genotyping is given as an Nx3 matrix, where N is the number of samples. Each row in the matrix\n",
    "# represents the genotyping of a specific individual. Since imputation is probabalistic, the genotyping is described as\n",
    "# three probabilities for having 0, 1 or 2 copies of the alternative allele, respectively (these are the same options\n",
    "# for the raw markers in the BED files, as described above).\n",
    "# For our purpose, we define a sample to be a carrier of the variant if there's at least 50% chance of it having any copy\n",
    "# of the alternative allele (under an assumed dominant effect), i.e. if the probability for 0 copies is smaller than 0.5.\n",
    "carrier_mask = (sample_variant_genotyping_probs[:, 0] <= 0.5)\n",
    "print('There are %d carriers of the variant.' % carrier_mask.sum())\n",
    "\n",
    "# We extract the node with ICD-10 coding E66, which stands for obesity.\n",
    "(_, ICD10_node), = ICD10_tree[ICD10_tree['coding'] == 'E66'].iterrows()\n",
    "# We create a mask vector, aligned to the samples used in imputation data, that would determine whether each sample is\n",
    "# inflicted with obesity.\n",
    "case_mask = pd.Series([(sample_index in ICD10_node['samples']) for sample_index in imputation_index.index], index = \\\n",
    "        imputation_index.index)\n",
    "control_mask = ~case_mask\n",
    "print('%d cases, %d controls.' % (case_mask.sum(), control_mask.sum()))\n",
    "\n",
    "# We construct a contingency table counting the number of sample with each combination of being either a carrier or\n",
    "# non-carrier of the allele, and being either of the case or the control group.\n",
    "contingency_table = pd.DataFrame([\n",
    "    [(carrier_mask & case_mask).sum(), (carrier_mask & control_mask).sum()],\n",
    "    [((~carrier_mask) & case_mask).sum(), ((~carrier_mask) & control_mask).sum()],\n",
    "], index = ['carriers', 'non_carriers'], columns = ['cases', 'controls'])\n",
    "display(contingency_table)\n",
    "\n",
    "# We run Fisher's exact test to test the reported association.\n",
    "print('Fisher\\'s exact test results: OR = %.2f, p-value = %.2g' % fisher_exact(contingency_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip:\n",
    "\n",
    "It is recommended to subscribe to the UKB-GENETICS@JISCMAIL.AC.UK mailing list (https://www.jiscmail.ac.uk/cgi-bin/webadmin?A0=UKB-GENETICS), where you can see the questions, answers and discussion of other researchers working with the UKBB genetic data, and also post your own questions regarding the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
