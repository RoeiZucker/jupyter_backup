{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53198775-8bbe-4f19-b142-117b7efbe5c1",
   "metadata": {},
   "source": [
    "# visualize token classifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df921989-122f-47cc-b123-9f3b602b615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 10:09:09.970994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-11 10:09:09.982610: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-11 10:09:09.986185: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-11 10:09:09.994781: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-11 10:09:12.608438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "import os\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a3281ab-ffe2-4af1-9a92-c94d9cc50f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_TRAIN_SAVE_PATH = \"unmasked_cpg_train\"\n",
    "# DATASET_TEST_SAVE_PATH = \"unmasked_cpg_test\"\n",
    "DATASET_TRAIN_SAVE_PATH = \"MR_DNA_50_train\"\n",
    "DATASET_TEST_SAVE_PATH = \"MR_DNA_50_test\"\n",
    "EVALUATION_SAMPLE_SIZE = 1000\n",
    "SAVE_PATH = \"/sci/nosnap/michall/roeizucker/jupyter_notebooks/Tom_Hope_Project/visualized_results/MR_DNA_50\"\n",
    "CHECKPOINTS_PATH = \"/sci/nosnap/michall/roeizucker/jupyter_notebooks/Tom_Hope_Project/InstaDeepAI/nucleotide-transformer-500m-1000g-MR_DNA_50\"\n",
    "NUCLEPTIDE_TRANSFORMER_500M_1000G_NAME = \"InstaDeepAI/nucleotide-transformer-500m-1000g\"\n",
    "MODEL_NAME = NUCLEPTIDE_TRANSFORMER_500M_1000G_NAME\n",
    "SUFFIX = \"MR_DNA_50\"\n",
    "BATCH_SIZE = 15\n",
    "EPOCH_NUM = 7\n",
    "MAX_TOKEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34fc2dce-7e0b-4d6a-8bf7-4a395c0af73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(SAVE_PATH):\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b3695a-6c9e-44e4-98b0-74a57319e37b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7202221f-0cd8-475e-ae93-0e98a39aa705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    # logits, labels = eval_pred\n",
    "    # predictions = np.argmax(logits, axis=-1)\n",
    "    # return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape((-1,))\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    predictions = predictions.reshape((-1,))\n",
    "    predictions = predictions[labels!=BLANK_LABLE_VALUE]\n",
    "    labels = labels[labels!=BLANK_LABLE_VALUE]\n",
    "\n",
    "    master_dict[\"predictiosn\"] = predictions\n",
    "    master_dict[\"references\"] = labels\n",
    "    return metric.compute(predictions=predictions, references=labels,average=\"weighted\")\n",
    "def show_for_num(num,dataset,trainer):\n",
    "    predict_dataset = Dataset.from_dict(dataset[num:num+1])\n",
    "    if (len(predict_dataset[0][\"labels\"])) != MAX_TOKEN:\n",
    "        return []\n",
    "    # input()\n",
    "    raw_pred, _, _ = trainer.predict(predict_dataset)\n",
    "    y_pred = np.argmax(raw_pred, axis=2)\n",
    "    counter = 0\n",
    "    flag = False\n",
    "    res = []\n",
    "    for pred,orig in zip(y_pred[0],np.array(dataset[num][\"labels\"])):\n",
    "        if orig==-100:\n",
    "            break\n",
    "        if pred != 0 or orig != 0:\n",
    "        # if pred != 0:\n",
    "            flag = True\n",
    "            # print(num,pred,orig,counter)\n",
    "            res.append((num,pred,orig,counter))\n",
    "        counter+=1\n",
    "    return res\n",
    "\n",
    "local_metric = load(\"accuracy\")\n",
    "\n",
    "def calc_for_num(trainer,dataset,count):\n",
    "    curr_res = []\n",
    "    for i in range(count):\n",
    "        curr_res.extend(show_for_num(i,dataset,trainer))\n",
    "    return curr_res\n",
    "\n",
    "def delete_me(eval_pred):\n",
    "    # print(eval_pred)\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape((-1,))\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    predictions = predictions.reshape((-1,))\n",
    "    predictions = predictions[labels!=-100]\n",
    "    labels = labels[labels!=-100]\n",
    "    return local_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def local_compute_metrics_avaraged(eval_pred,local_metric):\n",
    "    # print(eval_pred)\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape((-1,))\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    predictions = predictions.reshape((-1,))\n",
    "    predictions = predictions[labels!=-100]\n",
    "    labels = labels[labels!=-100]\n",
    "    return local_metric.compute(predictions=predictions, references=labels,average=None)\n",
    "\n",
    "def local_compute_metrics_non_avaraged(eval_pred,local_metric):\n",
    "    # print(eval_pred)\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape((-1,))\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    predictions = predictions.reshape((-1,))\n",
    "    predictions = predictions[labels!=-100]\n",
    "    labels = labels[labels!=-100]\n",
    "    return local_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def do_multiple_evals(regular_metrics,avaraged_metrics,model,dataset):\n",
    "    res = {}\n",
    "    for metric,name in regular_metrics:\n",
    "        try:\n",
    "            trainer = Trainer(model,args,compute_metrics=lambda eval_pred: local_compute_metrics_non_avaraged(eval_pred,metric))\n",
    "            res[name] = trainer.evaluate(Dataset.from_dict(dataset[0:count]))\n",
    "            # del trainer\n",
    "        finally:\n",
    "            del trainer\n",
    "    for metric,name in avaraged_metrics:\n",
    "        try:\n",
    "            trainer = Trainer(model,args,compute_metrics=lambda eval_pred: local_compute_metrics_avaraged(eval_pred,metric))\n",
    "            res[name] = trainer.evaluate(Dataset.from_dict(dataset[0:count]))\n",
    "        finally:\n",
    "            del trainer\n",
    "    return res\n",
    "def make_plot(col,suf):\n",
    "    temp_df = final_df[[\"name\",col]]\n",
    "    temp_df = temp_df[temp_df[\"name\"].str.endswith(suf)]\n",
    "    temp_df[\"step\"] = (temp_df[\"name\"].str.replace(\"checkpoint-\",\"\").str.replace(\"_\" + suf,\"\").astype(int))\n",
    "    \n",
    "    temp_df.sort_values(by=\"step\")[[col]].reset_index()[col].plot.line()\n",
    "    plt.title(col + \"-\" + suf)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab15ad9-303b-46e9-8052-2bed6d0bd096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_from_disk(DATASET_TRAIN_SAVE_PATH)\n",
    "test_dataset = load_from_disk(DATASET_TEST_SAVE_PATH)\n",
    "args = TrainingArguments(\n",
    "    f\"{MODEL_NAME}-{SUFFIX}\",\n",
    "    evaluation_strategy = \"no\",\n",
    "    do_eval=False,\n",
    "    # evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCH_NUM,\n",
    "    weight_decay=0.001,\n",
    "    # load_best_model_at_end=True,\n",
    "    # metric_for_best_model=METRIC,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f2f8b5-7165-4ae6-96a3-55ad1bcddf80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# final_results = []\n",
    "eval_results = []\n",
    "dir_names = []\n",
    "# TODO: add as constant\n",
    "avaraged_metrics = [(load(\"f1\"),\"f1\"),(load(\"recall\"),\"recall\"),(load(\"precision\"),\"precision\")]\n",
    "regular_metrics = [(load(\"accuracy\"),\"accuracy\")]\n",
    "\n",
    "count = EVALUATION_SAMPLE_SIZE\n",
    "# dataset = train_dataset\n",
    "\n",
    "\n",
    "dataset_num = 0\n",
    "dataset_names = [\"train\",\"test\"]\n",
    "for dataset in [train_dataset,test_dataset]:\n",
    "    for dir_name in os.listdir(CHECKPOINTS_PATH):\n",
    "        if \"checkpoint\" in dir_name:\n",
    "            dir_names.append(dir_name + \"_\" +dataset_names[dataset_num])\n",
    "            print(dir_name + \"_\" +dataset_names[dataset_num])\n",
    "            try:\n",
    "                curr_model = AutoModelForTokenClassification.from_pretrained(os.path.join(CHECKPOINTS_PATH,dir_name))\n",
    "                curr_trainer = Trainer(curr_model,args,compute_metrics = delete_me)\n",
    "                # final_results.append(calc_for_num(curr_trainer,dataset,count))\n",
    "                # eval_results.append(curr_trainer.evaluate(Dataset.from_dict(dataset[0:count]))[\"eval_f1\"])\n",
    "                eval_results.append(do_multiple_evals(regular_metrics,avaraged_metrics,curr_model,dataset))\n",
    "\n",
    "            finally:\n",
    "            # final_results.append()\n",
    "                del curr_model\n",
    "                del curr_trainer\n",
    "    dataset_num+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5745c62d-fa4b-4e38-8014-0af5fcac51a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sci/nosnap/michall/roeizucker/jupyter_notebooks/Tom_Hope_Project/InstaDeepAI/nucleotide-transformer-500m-1000g-unmasked_cpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(CHECKPOINTS_PATH)\n",
    "CHECKPOINTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26904db-1b20-42e8-ae2a-cf711675faea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m final_df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m2\u001b[39m:]:\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mmake_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     make_plot(score,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 93\u001b[0m, in \u001b[0;36mmake_plot\u001b[0;34m(col, suf)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_plot\u001b[39m(col,suf):\n\u001b[1;32m     92\u001b[0m     temp_df \u001b[38;5;241m=\u001b[39m final_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m,col]]\n\u001b[0;32m---> 93\u001b[0m     temp_df \u001b[38;5;241m=\u001b[39m temp_df[\u001b[43mtemp_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mendswith(suf)]\n\u001b[1;32m     94\u001b[0m     temp_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (temp_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint-\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suf,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n\u001b[1;32m     96\u001b[0m     temp_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m)[[col]]\u001b[38;5;241m.\u001b[39mreset_index()[col]\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mline()\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6297\u001b[0m ):\n\u001b[1;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/core/strings/accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/core/strings/accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# TODO: number of labels should be from parameters\n",
    "# final_df = pd.DataFrame([dir_names,final_results,eval_results]).T\n",
    "final_df = pd.DataFrame([dir_names,eval_results]).T\n",
    "# final_df.columns = ['name', 'res', 'score']\n",
    "final_df.columns = ['name', 'score']\n",
    "final_df[\"accuracy_score\"] = final_df[\"score\"].apply(lambda x:x[\"accuracy\"][\"eval_accuracy\"])\n",
    "final_df[\"f1_0\"] = final_df[\"score\"].apply(lambda x:x[\"f1\"][\"eval_f1\"][0])\n",
    "final_df[\"f1_1\"] = final_df[\"score\"].apply(lambda x:x[\"f1\"][\"eval_f1\"][1])\n",
    "# final_df[\"f1_2\"] = final_df[\"score\"].apply(lambda x:x[\"f1\"][\"eval_f1\"][2])\n",
    "final_df[\"recall_0\"] = final_df[\"score\"].apply(lambda x:x[\"recall\"][\"eval_recall\"][0])\n",
    "final_df[\"recall_1\"] = final_df[\"score\"].apply(lambda x:x[\"recall\"][\"eval_recall\"][1])\n",
    "# final_df[\"recall_2\"] = final_df[\"score\"].apply(lambda x:x[\"recall\"][\"eval_recall\"][2])\n",
    "final_df[\"precision_0\"] = final_df[\"score\"].apply(lambda x:x[\"precision\"][\"eval_precision\"][0])\n",
    "final_df[\"precision_1\"] = final_df[\"score\"].apply(lambda x:x[\"precision\"][\"eval_precision\"][1])\n",
    "# final_df[\"precision_2\"] = final_df[\"score\"].apply(lambda x:x[\"precision\"][\"eval_precision\"][2])\n",
    "skip = False\n",
    "for score in final_df.columns[2:]:\n",
    "    make_plot(score,\"train\")\n",
    "    make_plot(score,\"test\")\n",
    "    plt.legend([\"train\",\"test\"])\n",
    "    # plt.savefig(f\"{score}.png\")\n",
    "    plt.savefig(os.path.join(SAVE_PATH,score) + \"_score\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934dae00-f5d5-40c2-8f8d-db616426af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
