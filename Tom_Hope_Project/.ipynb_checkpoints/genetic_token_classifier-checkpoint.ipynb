{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a87b44-4406-4bbb-902b-c3436519f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from evaluate import load\n",
    "import datetime\n",
    "import os\n",
    "# from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5beb3215-1035-4319-a2d0-fe96f8c2b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change to work with classes?\n",
    "NUCLEPTIDE_TRANSFORMER_500M_1000G_NAME = \"InstaDeepAI/nucleotide-transformer-500m-1000g\"\n",
    "INSTADEEP_BASIC_RUN_MODELS = [NUCLEPTIDE_TRANSFORMER_500M_1000G_NAME]\n",
    "INSTADEEP_KMER_SIZE = 6\n",
    "INSTADEEP_BASIC_MAX_TOKEN_LENGTH = 1000\n",
    "\n",
    "#TODO: Change so that these values are taken from JSON\n",
    "TRAIN_PATH = \"table_browser_hg38_unmasked_CpG_train.csv\"\n",
    "TEST_PATH = \"table_browser_hg38_unmasked_CpG_test.csv\"\n",
    "MODEL_NAME = NUCLEPTIDE_TRANSFORMER_500M_1000G_NAME\n",
    "DO_DOWNSAMPLING = False\n",
    "LABLES_USED = [0,1]\n",
    "TRAIN_SIZE = 1\n",
    "BATCH_SIZE = 1\n",
    "SUFFIX = \"unmasked_cpg\"\n",
    "EPOCH_NUM = 10\n",
    "METRIC = \"None\"\n",
    "CONTINUE_FROM = \"\"\n",
    "DATASET_TRAIN_SAVE_PATH = \"unmasked_cpg_train\"\n",
    "DATASET_TEST_SAVE_PATH = \"unmasked_cpg_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3ba0f16-6c17-4d45-8d33-0960eafa5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6335df0b-fd36-485b-976e-69daa92676c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "train_df = train_df.head(int(len(train_df) *TRAIN_SIZE))\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1dee6d-8d2d-4e2a-a608-6114ef969477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_INSTADEEP_basic_label_seq_from_df(df):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for row_idx, row in df.iterrows():\n",
    "        if row_idx % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(str(int(100*(row_idx / len(df)))) + \"%\")\n",
    "\n",
    "        curr_label = row[\"labels\"]\n",
    "        # for i, seq in enumerate(row[\"result\"]):\n",
    "        #     curr_label.extend([row[\"stags\"][i]]*len(seq))\n",
    "        \n",
    "        label = np.zeros(len(curr_label)//INSTADEEP_KMER_SIZE,dtype=np.int64)\n",
    "        for i in range(0,len(curr_label),INSTADEEP_KMER_SIZE):\n",
    "            \n",
    "            for j in range(1,len(LABLES_USED)):\n",
    "                # TODO: consinder changing str(j) to something else\n",
    "                if i+INSTADEEP_KMER_SIZE <len(curr_label) and str(j) in curr_label[i:i+INSTADEEP_KMER_SIZE]:\n",
    "                    label[i//INSTADEEP_KMER_SIZE:i//INSTADEEP_KMER_SIZE+1] = j\n",
    "                    break\n",
    "            else: # unneeded\n",
    "                label[i//INSTADEEP_KMER_SIZE:i//INSTADEEP_KMER_SIZE+1] = 0\n",
    "        # seq_str = \"\".join(row[\"result\"])[:len(curr_label)]\n",
    "        seq_str = row[\"seq\"]\n",
    "\n",
    "        # TODO: check why sometimes seq length is not 1000\n",
    "        # TODO: check why sometimes seq is type float\n",
    "        if (len(str(seq_str))) != 6000 or (len(label)) != 1000: \n",
    "            continue\n",
    "        sequences.append(seq_str)\n",
    "        labels.append(label)\n",
    "    return sequences, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4aae6c-a16c-4e12-9630-f7a8e1d5e651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n"
     ]
    }
   ],
   "source": [
    "train_sequences,train_labels = create_INSTADEEP_basic_label_seq_from_df(train_df)\n",
    "test_sequences, test_labels = create_INSTADEEP_basic_label_seq_from_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c00eaa2d-7429-4d5d-9969-43b1ab9cb137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    AGGTAGCTCTACTGCCTCCTCTTAAAACCAACAAAGGAAAGAGAGA...\n",
       "1    CAGCCTGGGCGACAGAGTGAGTCTAAAAAAAATAAAAAAGGAATTC...\n",
       "Name: seq, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)[\"seq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5c541b-7b77-41d1-b4d5-9d80b8343ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets_instadeep_basic(seq,labels,tokenizer):\n",
    "    tokenized_dataset = tokenizer(\n",
    "        seq,\n",
    "        max_length=INSTADEEP_BASIC_MAX_TOKEN_LENGTH,\n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "    dataset = Dataset.from_dict(tokenized_dataset)\n",
    "    dataset = dataset.add_column(\"labels\", labels)\n",
    "    return dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "train_dataset = create_datasets_instadeep_basic(train_sequences,train_labels,tokenizer)\n",
    "test_dataset = create_datasets_instadeep_basic(test_sequences, test_labels,tokenizer)\n",
    "#TODO: change so if already saved to disk, load existing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a74b0dc7-d404-493c-ac95-215bc34a2d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'table_browser_hg38_unmasked_CpG_train.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e52c6f2-3cef-4468-8f16-a7ef5b23bf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e8551c1c11428d89d9be4eee4d103d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/33423 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497418eed12f4241ae69c8c6767c44f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/11138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: check if resaving changes results\n",
    "train_dataset.save_to_disk(DATASET_TRAIN_SAVE_PATH)\n",
    "test_dataset.save_to_disk(DATASET_TEST_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54d3289e-99af-46d8-8b44-06c904b16293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n",
      "0 label: 30209385\n",
      "1 label: 3213615\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "for i in range(len(train_dataset)):\n",
    "    if i % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(str(int(100*(i / len(train_dataset)))) + \"%\")\n",
    "    for val in train_dataset[i][\"labels\"]:\n",
    "        if val not in dic:\n",
    "            dic[val] = 0\n",
    "        dic[val]+= 1\n",
    "for label in dic:\n",
    "    print(f\"{label} label:\",dic[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c2995d3-7932-4196-bcec-223f4fe536e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1096dd90-5a81-479f-9f6a-9fe2bc0f4f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at InstaDeepAI/nucleotide-transformer-500m-1000g and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME,num_labels=len(LABLES_USED), device_map=\"auto\")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0832d12-7f41-4d8f-9761-691a5ad7508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "# TODO: USE their parameters and LORA. copy from them\n",
    "args = TrainingArguments(\n",
    "    f\"{MODEL_NAME}-{SUFFIX}\",\n",
    "    evaluation_strategy = \"no\",\n",
    "    do_eval=False,\n",
    "    # evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=3*batch_size,\n",
    "    #per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=EPOCH_NUM,\n",
    "    weight_decay=0.001,\n",
    "    # load_best_model_at_end=True,\n",
    "    metric_for_best_model=METRIC,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd808074-ce3e-4851-a917-c464b5df3662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1023758/2344023472.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a0df1-a134-488c-bdd2-066f564d77cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18539' max='334230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 18539/334230 3:07:20 < 53:10:27, 1.65 it/s, Epoch 0.55/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.126700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.098600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.102300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.082100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.091300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.086300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.081400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if CONTINUE_FROM == \"\":\n",
    "    trainer.train()\n",
    "else:\n",
    "    trainer.train(resume_from_checkpoint=CONTINUE_FROM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bdadc1-af9b-4f44-8e22-95d8575a2df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
