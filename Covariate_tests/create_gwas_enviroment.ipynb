{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284daed9",
   "metadata": {},
   "source": [
    "# Create different GWAS enviroments for covariate tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776e781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76ba64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covar constants\n",
    "INCLUDED_COVARS = [\"sex\",\"year_of_birth\",\"AC\",\"batch\"]\n",
    "AC_VALS = ['AC_stockport_pilot','AC_manchester','AC_oxford','AC_cardiff','AC_glasgow','AC_edinburgh','AC_stoke','AC_reading','AC_bury','AC_newcastle','AC_bristol','AC_barts','AC_nottingham','AC_sheffield','AC_liverpool','AC_middlesborough','AC_hounslow','AC_croydon','AC_birmingham','AC_swansea','AC_wrexham','AC_cheadle_revisit','AC_cheadle_imaging','AC_reading_imaging','AC_newcastle_imaging']\n",
    "BATCH_VALS = ['batch_Batch_b001','batch_Batch_b002','batch_Batch_b003','batch_Batch_b004','batch_Batch_b005','batch_Batch_b006','batch_Batch_b007','batch_Batch_b008','batch_Batch_b009','batch_Batch_b010','batch_Batch_b011','batch_Batch_b012','batch_Batch_b013','batch_Batch_b014','batch_Batch_b015','batch_Batch_b016','batch_Batch_b017','batch_Batch_b018','batch_Batch_b019','batch_Batch_b020','batch_Batch_b021','batch_Batch_b022','batch_Batch_b023','batch_Batch_b024','batch_Batch_b025','batch_Batch_b026','batch_Batch_b027','batch_Batch_b028','batch_Batch_b029','batch_Batch_b030','batch_Batch_b031','batch_Batch_b032','batch_Batch_b033','batch_Batch_b034','batch_Batch_b035','batch_Batch_b036','batch_Batch_b037','batch_Batch_b038','batch_Batch_b039','batch_Batch_b040','batch_Batch_b041','batch_Batch_b042','batch_Batch_b043','batch_Batch_b044','batch_Batch_b045','batch_Batch_b046','batch_Batch_b047','batch_Batch_b048','batch_Batch_b049','batch_Batch_b050','batch_Batch_b051','batch_Batch_b052','batch_Batch_b053','batch_Batch_b054','batch_Batch_b055','batch_Batch_b056','batch_Batch_b057','batch_Batch_b058','batch_Batch_b059','batch_Batch_b060','batch_Batch_b061','batch_Batch_b062','batch_Batch_b063','batch_Batch_b064','batch_Batch_b065','batch_Batch_b066','batch_Batch_b067','batch_Batch_b068','batch_Batch_b069','batch_Batch_b070','batch_Batch_b071','batch_Batch_b072','batch_Batch_b073','batch_Batch_b074','batch_Batch_b075','batch_Batch_b076','batch_Batch_b077','batch_Batch_b078','batch_Batch_b079','batch_Batch_b080','batch_Batch_b081','batch_Batch_b082','batch_Batch_b083','batch_Batch_b084','batch_Batch_b085','batch_Batch_b086','batch_Batch_b087','batch_Batch_b088','batch_Batch_b089','batch_Batch_b090','batch_Batch_b091','batch_Batch_b092','batch_Batch_b093','batch_Batch_b094','batch_Batch_b095','batch_UKBiLEVEAX_b1','batch_UKBiLEVEAX_b10','batch_UKBiLEVEAX_b11','batch_UKBiLEVEAX_b3','batch_UKBiLEVEAX_b4','batch_UKBiLEVEAX_b5','batch_UKBiLEVEAX_b6','batch_UKBiLEVEAX_b7','batch_UKBiLEVEAX_b8','batch_UKBiLEVEAX_b9']\n",
    "NUMBER_OF_PC = [0,1,5,10,20,40]\n",
    "\n",
    "# gwas constants \n",
    "# PHENOTYPES = [\"Multiple_sclerosis\",\"Diastolic_blood_pressure\"]\n",
    "# PHENOTYPES_PAIR = [(\"Diastolic_blood_pressure\",\"PHENO1.glm.linear\"),(\"Multiple_sclerosis\",\"PHENO1.glm.logistic\")]\n",
    "PHENOTYPES_PAIR = [(\"Diastolic_blood_pressure\",\"PHENO1.glm.linear\"),(\"Multiple_sclerosis\",\"PHENO1.glm.logistic\"),(\"hypertension\",'PHENO1.glm.logistic')]\n",
    "# PHENOTYPES_PAIR = [(\"Multiple_sclerosis\",\"PHENO1.glm.logistic\")]\n",
    "\n",
    "\n",
    "\n",
    "PHENOTYPES = list(map(lambda x:x[0],PHENOTYPES_PAIR))\n",
    "# CHROMOSOMES =  [1]\n",
    "CHROMOSOMES = list(range(1,23))\n",
    "RESULT_SUFFIX = \"PHENO1.glm.logistic\"\n",
    "NO_COVAR_CHAR = \"no_covar\"\n",
    "\n",
    "# scripts constants \n",
    "VALUE_AT_END_OF_PHENOTYPES = 'const'\n",
    "PLINK_PATH = \"/cs/usr/nadavb/third_party/plink2\"\n",
    "MEM_USED = 30\n",
    "MEM_USED_LONG = 30000\n",
    "CPU_USED = 30\n",
    "BATCH_LENGTH = 250\n",
    "MAX_JOBS_BEFORE_SUBMITTING_NEW_ARRAY = 200\n",
    "DATA_FILE_NAME = \"data_file_2_22_chromosomes.csv\"\n",
    "SAMPLE_FILE = \"/cs/biobank-genetics/EGAD00010001474/ukb26664_imp_chr1_v3.sample\"\n",
    "PLINK_GENE_FILES = 0\n",
    "BGEN_GENE_FILES = 1\n",
    "HADASSA_PLINK = 2\n",
    "\n",
    "COMBINE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f3889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636881a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6849b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "PROJECT_PATH = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK\"\n",
    "DATASET_FILE = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/ukbb_dataset.csv\"\n",
    "GENE_FILE_TYPE = HADASSA_PLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec3091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20251563",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATASET_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2eb472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>eid</th>\n",
       "      <th>Diastolic_blood_pressure</th>\n",
       "      <th>Multiple_sclerosis</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>const</th>\n",
       "      <th>sex</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>...</th>\n",
       "      <th>batch_UKBiLEVEAX_b1</th>\n",
       "      <th>batch_UKBiLEVEAX_b10</th>\n",
       "      <th>batch_UKBiLEVEAX_b11</th>\n",
       "      <th>batch_UKBiLEVEAX_b3</th>\n",
       "      <th>batch_UKBiLEVEAX_b4</th>\n",
       "      <th>batch_UKBiLEVEAX_b5</th>\n",
       "      <th>batch_UKBiLEVEAX_b6</th>\n",
       "      <th>batch_UKBiLEVEAX_b7</th>\n",
       "      <th>batch_UKBiLEVEAX_b8</th>\n",
       "      <th>batch_UKBiLEVEAX_b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5895328</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>-12.53270</td>\n",
       "      <td>4.235220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5764375</td>\n",
       "      <td>94.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>-12.33790</td>\n",
       "      <td>3.061120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5503073</td>\n",
       "      <td>84.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>-11.85050</td>\n",
       "      <td>5.194030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2563626</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>-11.97490</td>\n",
       "      <td>3.477800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4980832</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>-8.73549</td>\n",
       "      <td>4.980050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333627</th>\n",
       "      <td>502513</td>\n",
       "      <td>2243883</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>-13.83960</td>\n",
       "      <td>6.899070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333628</th>\n",
       "      <td>502515</td>\n",
       "      <td>3570729</td>\n",
       "      <td>82.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>-15.15060</td>\n",
       "      <td>5.265920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333629</th>\n",
       "      <td>502516</td>\n",
       "      <td>1663456</td>\n",
       "      <td>79.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>-11.59990</td>\n",
       "      <td>2.911470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333630</th>\n",
       "      <td>502517</td>\n",
       "      <td>3118989</td>\n",
       "      <td>79.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>-13.72620</td>\n",
       "      <td>0.917067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333631</th>\n",
       "      <td>502519</td>\n",
       "      <td>4573284</td>\n",
       "      <td>94.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>-12.71160</td>\n",
       "      <td>1.226900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333632 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample_index      eid  Diastolic_blood_pressure Multiple_sclerosis  \\\n",
       "0                  0  5895328                      80.0              False   \n",
       "1                  1  5764375                      94.0              False   \n",
       "2                  2  5503073                      84.0              False   \n",
       "3                  3  2563626                      80.0              False   \n",
       "4                  4  4980832                      74.0              False   \n",
       "...              ...      ...                       ...                ...   \n",
       "333627        502513  2243883                      75.0              False   \n",
       "333628        502515  3570729                      82.0              False   \n",
       "333629        502516  1663456                      79.0              False   \n",
       "333630        502517  3118989                      79.0              False   \n",
       "333631        502519  4573284                      94.0              False   \n",
       "\n",
       "       hypertension  const  sex  year_of_birth       PC1       PC2  ...  \\\n",
       "0             False    1.0  1.0         1942.0 -12.53270  4.235220  ...   \n",
       "1             False    1.0  0.0         1951.0 -12.33790  3.061120  ...   \n",
       "2              True    1.0  1.0         1944.0 -11.85050  5.194030  ...   \n",
       "3              True    1.0  1.0         1950.0 -11.97490  3.477800  ...   \n",
       "4             False    1.0  1.0         1948.0  -8.73549  4.980050  ...   \n",
       "...             ...    ...  ...            ...       ...       ...  ...   \n",
       "333627         True    1.0  1.0         1949.0 -13.83960  6.899070  ...   \n",
       "333628        False    1.0  1.0         1955.0 -15.15060  5.265920  ...   \n",
       "333629        False    1.0  1.0         1941.0 -11.59990  2.911470  ...   \n",
       "333630         True    1.0  0.0         1942.0 -13.72620  0.917067  ...   \n",
       "333631        False    1.0  0.0         1950.0 -12.71160  1.226900  ...   \n",
       "\n",
       "        batch_UKBiLEVEAX_b1  batch_UKBiLEVEAX_b10  batch_UKBiLEVEAX_b11  \\\n",
       "0                       0.0                   0.0                   0.0   \n",
       "1                       0.0                   0.0                   0.0   \n",
       "2                       0.0                   0.0                   0.0   \n",
       "3                       0.0                   0.0                   0.0   \n",
       "4                       0.0                   0.0                   0.0   \n",
       "...                     ...                   ...                   ...   \n",
       "333627                  0.0                   0.0                   0.0   \n",
       "333628                  0.0                   0.0                   0.0   \n",
       "333629                  0.0                   0.0                   0.0   \n",
       "333630                  0.0                   0.0                   0.0   \n",
       "333631                  0.0                   0.0                   0.0   \n",
       "\n",
       "        batch_UKBiLEVEAX_b3  batch_UKBiLEVEAX_b4  batch_UKBiLEVEAX_b5  \\\n",
       "0                       0.0                  0.0                  0.0   \n",
       "1                       0.0                  0.0                  0.0   \n",
       "2                       0.0                  0.0                  0.0   \n",
       "3                       0.0                  0.0                  0.0   \n",
       "4                       0.0                  0.0                  0.0   \n",
       "...                     ...                  ...                  ...   \n",
       "333627                  0.0                  0.0                  0.0   \n",
       "333628                  0.0                  0.0                  0.0   \n",
       "333629                  0.0                  0.0                  0.0   \n",
       "333630                  0.0                  0.0                  0.0   \n",
       "333631                  0.0                  0.0                  0.0   \n",
       "\n",
       "        batch_UKBiLEVEAX_b6  batch_UKBiLEVEAX_b7  batch_UKBiLEVEAX_b8  \\\n",
       "0                       0.0                  0.0                  0.0   \n",
       "1                       0.0                  0.0                  0.0   \n",
       "2                       0.0                  0.0                  0.0   \n",
       "3                       0.0                  0.0                  0.0   \n",
       "4                       0.0                  0.0                  0.0   \n",
       "...                     ...                  ...                  ...   \n",
       "333627                  0.0                  0.0                  0.0   \n",
       "333628                  0.0                  0.0                  0.0   \n",
       "333629                  0.0                  0.0                  0.0   \n",
       "333630                  0.0                  0.0                  0.0   \n",
       "333631                  0.0                  0.0                  0.0   \n",
       "\n",
       "        batch_UKBiLEVEAX_b9  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "...                     ...  \n",
       "333627                  0.0  \n",
       "333628                  0.0  \n",
       "333629                  0.0  \n",
       "333630                  0.0  \n",
       "333631                  0.0  \n",
       "\n",
       "[333632 rows x 178 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c07dc059",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PROJECT_PATH):\n",
    "    !mkdir {PROJECT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd636d",
   "metadata": {},
   "source": [
    "## create covariate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ac406d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_covar_file(covar_list:list,file_name:str,dataset:pd.DataFrame):\n",
    "    if os.path.exists(file_name):\n",
    "        return\n",
    "\n",
    "    covariate_values = dataset[['eid', 'eid'] + [covariate_col for covariate_col in covar_list if \\\n",
    "            covariate_col != 'const']].dropna()\n",
    "    covariate_values.to_csv(file_name, header = False, index = False, sep = '\\t')\n",
    "\n",
    "\n",
    "def get_covar_partial_name(covars_to_add,number_of_pcs):\n",
    "    file_name = str(covars_to_add).replace(\", \",\"_\").strip(\"[]\").replace(\"'\",\"\") + f\"_{number_of_pcs}_PC\"\n",
    "    if file_name[0] != \"_\":\n",
    "        file_name = \"_\" + file_name\n",
    "    return file_name\n",
    "\n",
    "def get_covar_file_name(covars_to_add,number_of_pcs):\n",
    "    file_name = get_covar_partial_name(covars_to_add,number_of_pcs)\n",
    "    file_name = os.path.join(PROJECT_PATH, \"covariates\" + file_name + \".txt\")\n",
    "    return file_name\n",
    "    \n",
    "def create_enviroment(number_of_pcs:int,covars_to_add:list,dataset:pd.DataFrame):\n",
    "    covar_list = []\n",
    "    for covar in covars_to_add:\n",
    "        if covar == \"AC\":\n",
    "            covar_list.extend(AC_VALS)\n",
    "        elif covar == \"batch\":\n",
    "            covar_list.extend(BATCH_VALS)\n",
    "        else:\n",
    "            covar_list.append(covar)\n",
    "    for i in range(number_of_pcs):\n",
    "        covar_list.append(f\"PC{i+1}\")\n",
    "    file_name = get_covar_file_name(covars_to_add,number_of_pcs)\n",
    "#     print(file_name)\n",
    "#     print(str(covars_to_add).replace(\", \",\"_\").strip(\"[]\").replace(\"'\",\"\") + f\"_{number_of_pcs}_PC_GWAS\")\n",
    "#     !mkdir {dir_name}\n",
    "    create_covar_file(covar_list,file_name,dataset)\n",
    "    \n",
    "def convert_num_to_binary_list(num:int,final_len):\n",
    "#     return bin(num)\n",
    "    res = [int(i) for i in list('{0:0b}'.format(num))]\n",
    "    return [0]*(final_len - len(res)) +res\n",
    "\n",
    "\n",
    "def get_covars_to_add(val):\n",
    "    covars_to_add = []\n",
    "#     create a list of covars for combination (binary list)\n",
    "    for i,insert in enumerate(convert_num_to_binary_list(val,len(INCLUDED_COVARS))):\n",
    "        if insert:\n",
    "            covars_to_add.append(INCLUDED_COVARS[i])\n",
    "    return covars_to_add\n",
    "\n",
    "# create all combinations of covars and PC num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a663e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/covariates_0_PC.txt\", sep = '\\t') \n",
    "df2 = pd.read_csv(\"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/covariates_5_PC.txt\", sep = '\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197531e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc0d298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 16\n",
      "1 / 16\n",
      "2 / 16\n",
      "3 / 16\n",
      "4 / 16\n",
      "5 / 16\n",
      "6 / 16\n",
      "7 / 16\n",
      "8 / 16\n",
      "9 / 16\n",
      "10 / 16\n",
      "11 / 16\n",
      "12 / 16\n",
      "13 / 16\n",
      "14 / 16\n",
      "15 / 16\n"
     ]
    }
   ],
   "source": [
    "for val in range(2**len(INCLUDED_COVARS)):\n",
    "    print (val,\"/\",2**len(INCLUDED_COVARS))\n",
    "    covars_to_add = get_covars_to_add(val)\n",
    "    for pc_num in NUMBER_OF_PC:\n",
    "        create_enviroment(pc_num,covars_to_add,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bf813",
   "metadata": {},
   "source": [
    "## create other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449c90f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/results’: File exists\n",
      "mkdir: cannot create directory ‘/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/phenotypes’: File exists\n",
      "Diastolic_blood_pressure\n",
      "Multiple_sclerosis\n",
      "hypertension\n"
     ]
    }
   ],
   "source": [
    "# dataset[[\"I10\"]]\n",
    "def create_files(gwas_path,dataset):\n",
    "    !mkdir {gwas_path}/results\n",
    "    !mkdir {gwas_path}/phenotypes\n",
    "#     !cp /cs/labs/michall/roeizucker/10krun/runs/0:11/GWAS_delete_me/covariates.txt {gwas_path}/covariates.txt\n",
    "#     !cd {gwas_path}\n",
    "#     dataset = pd.read_csv(phen_path)\n",
    "    for phenotype_col in PHENOTYPES:\n",
    "        print(phenotype_col)\n",
    "        file_name = phenotype_col.lower().replace(' ', '_').replace('-', '_') + '.txt'\n",
    "        values = dataset[['eid', 'eid', phenotype_col]].dropna()\n",
    "        values[phenotype_col] = values[phenotype_col].astype(float)\n",
    "        if len(values[phenotype_col].value_counts()) == 2:\n",
    "            values[phenotype_col] = values[phenotype_col] + 1\n",
    "        values.to_csv(os.path.join(f\"{gwas_path}/phenotypes\", file_name), \\\n",
    "            header = False, index = False, sep = '\\t')\n",
    "create_files(PROJECT_PATH,dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11432e05",
   "metadata": {},
   "source": [
    "### create data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685ff855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = os.path.join(PROJECT_PATH, DATA_FILE_NAME)\n",
    "mediator_script_path = os.path.join(PROJECT_PATH , \"mediator.py\")\n",
    "master_script_path = os.path.join(PROJECT_PATH , \"master.sh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c24eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a29b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_the_data_file(phenotype_cols,gwas_path,data_file_path):\n",
    "    values = []\n",
    "    last_counter = 0\n",
    "    cur_phen_counter = 0\n",
    "    counter = 0\n",
    "    for j in CHROMOSOMES:\n",
    "        base_path =  gwas_path\n",
    "        if GENE_FILE_TYPE == BGEN_GENE_FILES:\n",
    "            partial_path = f\"/cs/biobank-genetics/EGAD00010001474/ukb_imp_chr{j}_v3.bgen\"\n",
    "        elif GENE_FILE_TYPE == PLINK_GENE_FILES:\n",
    "            partial_path = f\"/cs/labs/michall/roeizucker/plink_results/reduced_snps2/small_ch{j}\"\n",
    "        elif GENE_FILE_TYPE == HADASSA_PLINK:\n",
    "            partial_path = f\"/cs/snapless/michall/hadasak/improve_PRS/bed_files/chr{j}_imputed_snp_id_filtered\"\n",
    "        for phen in phenotype_cols:        \n",
    "            for val in range(2**len(INCLUDED_COVARS)):\n",
    "                covars_to_add = get_covars_to_add(val)\n",
    "                for pc_num in NUMBER_OF_PC:\n",
    "                    if pc_num == 0 and len(covars_to_add) == 0:\n",
    "                        continue\n",
    "                    covar_file_name = get_covar_file_name(covars_to_add,pc_num)           \n",
    "                    covar_partial_name = get_covar_partial_name(covars_to_add,pc_num)\n",
    "                    if os.path.exists(os.path.join(base_path ,f\"results/{covar_partial_name}_{phen.lower()}_chr{j}.PHENO1.glm.logistic\")) or \\\n",
    "                    os.path.exists(os.path.join(base_path ,f\"results/{covar_partial_name}_{phen.lower()}_chr{j}.PHENO1.glm.linear\")):\n",
    "                            continue\n",
    "                    \n",
    "                    values.append([counter,os.path.join(base_path, \"phenotypes/\"+ phen.lower() + \".txt\"),\n",
    "                                   os.path.join(base_path, f\"results/{covar_partial_name}_{phen.lower()}_chr{j}\"),\n",
    "                                   partial_path,covar_file_name,j])\n",
    "            counter+=1\n",
    "            if os.path.exists(os.path.join(base_path ,f\"results/{NO_COVAR_CHAR}_{phen.lower()}_chr{j}.PHENO1.glm.logistic\"))  or \\\n",
    "            os.path.exists(os.path.join(base_path ,f\"results/{covar_partial_name}_{phen.lower()}_chr{j}.PHENO1.glm.linear\")):\n",
    "                continue\n",
    "            values.append([counter,os.path.join(base_path, \"phenotypes/\"+ phen.lower() + \".txt\"),\n",
    "                                   os.path.join(base_path, f\"results/{NO_COVAR_CHAR}_{phen.lower()}_chr{j}\"),\n",
    "                                   partial_path,NO_COVAR_CHAR,j])\n",
    "        cur_phen_counter+=1\n",
    "#         if cur_phen_counter%BATCH_LENGTH == 0:\n",
    "#             values[last_counter:counter] = sorted(values[last_counter:counter],key = lambda x:x[-1])\n",
    "#             last_counter = counter\n",
    "    df = pd.DataFrame(values, columns=[\"unsorted_counter\",\"phenotype_path\",\"output_path\",\"partial_chromosome_file_path\", \"covariates\",\"chr\"])\n",
    "    df.to_csv(data_file_path)\n",
    "create_the_data_file(PHENOTYPES,PROJECT_PATH,data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a5592a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea6ee05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>unsorted_counter</th>\n",
       "      <th>phenotype_path</th>\n",
       "      <th>output_path</th>\n",
       "      <th>partial_chromosome_file_path</th>\n",
       "      <th>covariates</th>\n",
       "      <th>chr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, unsorted_counter, phenotype_path, output_path, partial_chromosome_file_path, covariates, chr]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_curr = pd.read_csv(data_file_path)\n",
    "df_curr\n",
    "# list(df_curr[df_curr[\"output_path\"].str.contains(\"_year_of_birth_batch_5_PC_i10_chr4\")][\"output_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e4da0a",
   "metadata": {},
   "source": [
    "### create scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ec1a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to run:\n",
      "sbatch --array=0-263 --mem=32g -c30 --time=3-0 --requeue --killable --wrap=\"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/master.sh 0\"\n"
     ]
    }
   ],
   "source": [
    "def write_mediator_script(mediator_script_path,data_file_path,gwas_path,master_script_path):\n",
    "    with open(mediator_script_path, \"w\") as mediator_file:\n",
    "        mediator_file.write(f'''import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "butch_num = int(sys.argv[1]) \n",
    "curr_task = int(sys.argv[2])\n",
    "BATCH_LENGTH = {BATCH_LENGTH}\n",
    "SKIP_POINT = {MAX_JOBS_BEFORE_SUBMITTING_NEW_ARRAY}\n",
    "PLINK_PATH = \"/cs/usr/nadavb/third_party/plink2\"\n",
    "\n",
    "data_file_path = \"{data_file_path}\"\n",
    "df = pd.read_csv(data_file_path)\n",
    "print(df.loc[butch_num * BATCH_LENGTH + curr_task])\n",
    "val = df.loc[butch_num * BATCH_LENGTH + curr_task]\n",
    "location = butch_num * BATCH_LENGTH + curr_task\n",
    "SAMPLE_FILE = \"/cs/biobank-genetics/EGAD00010001474/ukb26664_imp_chr\" + str(df.loc[location].chr) + \"_v3.sample\"\n",
    "\n",
    "if {GENE_FILE_TYPE == BGEN_GENE_FILES}:\n",
    "    command_base = PLINK_PATH + \" --bgen \" + df.loc[location].partial_chromosome_file_path + \" --sample \" + SAMPLE_FILE\n",
    "elif {GENE_FILE_TYPE == PLINK_GENE_FILES}:\n",
    "    command_base = PLINK_PATH + \" --bed \" + df.loc[location].partial_chromosome_file_path + \".bed --bim \" + df.loc[location].partial_chromosome_file_path + \".bim --fam \"+df.loc[location].partial_chromosome_file_path + \".fam\"\n",
    "elif {GENE_FILE_TYPE == HADASSA_PLINK}:\n",
    "    command_base = PLINK_PATH + \" --bed \" + df.loc[location].partial_chromosome_file_path + \".bed --bim \" + df.loc[location].partial_chromosome_file_path + \".bim --fam \"+df.loc[location].partial_chromosome_file_path + \".fam\"\n",
    "if curr_task == SKIP_POINT and location < 30500:\n",
    "    new_batch  = butch_num + 1\n",
    "    if not os.path.isfile(os.path.join(\"{gwas_path}\", \"_\" + str(new_batch) + \"_flag\")):\n",
    "        os.system(\"sbatch --array=0-\"+str(BATCH_LENGTH - 1)+\" --mem={MEM_USED + 2}g -c{CPU_USED} --time=3-0 --killable --requeue --wrap=\\\\\"{master_script_path} \"+str(new_batch)+\"\\\\\"\")\n",
    "if location < 30500:\n",
    "    if df.loc[location].covariates != \"{NO_COVAR_CHAR}\":\n",
    "        print(command_base +\" --pheno \" + df.loc[location].phenotype_path + \" --covar \" + df.loc[location].covariates + \"  --out  \" + df.loc[location].output_path + \" --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads {CPU_USED} --memory {MEM_USED_LONG}\",flush=True)\n",
    "        os.system(command_base +\" --pheno \" + df.loc[location].phenotype_path + \" --covar \" + df.loc[location].covariates + \"  --out  \" + df.loc[location].output_path + \" --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads {CPU_USED} --memory {MEM_USED_LONG}\")\n",
    "        print(\"done!\")\n",
    "    else:\n",
    "        print(command_base +\" --pheno \" + df.loc[location].phenotype_path + \" --out  \" + df.loc[location].output_path + \" --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads {CPU_USED} --memory {MEM_USED_LONG}\",flush=True)\n",
    "        os.system(command_base +\" --pheno \" + df.loc[location].phenotype_path + \" --out  \" + df.loc[location].output_path + \" --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads {CPU_USED} --memory {MEM_USED_LONG}\")\n",
    "        print(\"done!\")\n",
    "''')\n",
    "\n",
    "def write_master_script(master_script_path,mediator_script_path,gwas_path):\n",
    "    with open(master_script_path, \"w\") as master_file:\n",
    "        master_file.write(f'''\n",
    "f1=\"{os.path.join(gwas_path,\"_$1_flag\")}\"\n",
    "if [ ! -f \"$f1\"  ]\n",
    "then \n",
    "    touch {os.path.join(gwas_path,\"_$1_flag\")}\n",
    "fi\n",
    "python {mediator_script_path} $1 $SLURM_ARRAY_TASK_ID\n",
    "''')\n",
    "    !chmod 744 {master_script_path}\n",
    "write_mediator_script(mediator_script_path,data_file_path,PROJECT_PATH,master_script_path)\n",
    "write_master_script(master_script_path,mediator_script_path,PROJECT_PATH)\n",
    "print(f'''how to run:\n",
    "sbatch --array=0-263 --mem={MEM_USED + 2}g -c{CPU_USED} --time=3-0 --requeue --killable --wrap=\"{master_script_path} 0\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f31c85a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1470108841.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_7771/1470108841.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    sbatch --array=0-15 --mem=32g -c30 --time=3-0 --requeue --killable --wrap=\"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/master.sh 0\"\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sbatch --array=0-1 --mem=32g -c30 --time=3-0 --requeue --killable --wrap=\"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/master.sh 0\"\n",
    "\n",
    "!cat {mediator_script_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tests\n",
    "# df = pd.read_csv(\"/sci/nosnap/michall/roeizucker/covar_tests/results/_0_PC_i10_chr1.PHENO1.glm.logistic\",sep=\"\\t\")\n",
    "# df1 = pd.read_csv(\"/sci/nosnap/michall/roeizucker/covar_tests/results/_40_PC_i10_chr1.PHENO1.glm.logistic\",sep=\"\\t\")\n",
    "# # df = df[df[\"P\"] > 0]\n",
    "# # df1 = df1[df1[\"P\"] > 0]\n",
    "# # df[\"P\"].idxmin()\n",
    "# print(df.loc[[df[\"P\"].idxmin()]])\n",
    "# print(df1.loc[[df1[\"P\"].idxmin()]])\n",
    "if not COMBINE:\n",
    "    input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de4c68",
   "metadata": {},
   "source": [
    "## combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa14417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/results_Multiple_sclerosis.csv\n"
     ]
    }
   ],
   "source": [
    "for phen_pair in PHENOTYPES_PAIR:\n",
    "    if phen_pair[0] != \"Multiple_sclerosis\":\n",
    "        continue\n",
    "    failed = False\n",
    "    dfs = []\n",
    "    for j in CHROMOSOMES:    \n",
    "        if j == 2:\n",
    "            continue\n",
    "#     for j in CHROMOSOMES:    \n",
    "        for val in range(2**len(INCLUDED_COVARS)):\n",
    "            covars_to_add = get_covars_to_add(val)\n",
    "            for pc_num in NUMBER_OF_PC:\n",
    "                if pc_num == 0 and len(covars_to_add) == 0:\n",
    "                    continue\n",
    "                covar_file_name = get_covar_file_name(covars_to_add,pc_num)           \n",
    "                covar_partial_name = get_covar_partial_name(covars_to_add,pc_num)\n",
    "                result_file_path = os.path.join(PROJECT_PATH, f\"results/{covar_partial_name}_{phen_pair[0].lower()}_chr{j}.{phen_pair[1]}\")\n",
    "                if not os.path.exists(result_file_path):\n",
    "                    print(\"file does not exist:\",result_file_path)\n",
    "                    failed = True\n",
    "                    continue\n",
    "                try:\n",
    "                    df = pd.read_csv(os.path.join(PROJECT_PATH, f\"results/{covar_partial_name}_{phen_pair[0].lower()}_chr{j}.{phen_pair[1]}\"),sep=\"\\t\")\n",
    "                except:\n",
    "                    failed = True\n",
    "                    print(\"error for\",result_file_path)\n",
    "                    continue\n",
    "                for covar in INCLUDED_COVARS:\n",
    "                    df[covar] = 0\n",
    "                for covar in covars_to_add:\n",
    "                    df[covar] = 1\n",
    "                df[\"covars\"] = (\"_\".join(covars_to_add))\n",
    "                df[\"pc_num\"] = pc_num\n",
    "                dfs.append(df)\n",
    "            covar_file_name = get_covar_file_name(covars_to_add,pc_num)\n",
    "        df = pd.read_csv(os.path.join(PROJECT_PATH, f\"results/{NO_COVAR_CHAR}_{phen_pair[0].lower()}_chr{j}.{phen_pair[1]}\"),sep=\"\\t\")\n",
    "        df[\"covars\"] = \"\"\n",
    "        df[\"pc_num\"] = 0\n",
    "        dfs.append(df)\n",
    "    if not failed:\n",
    "        master_df = pd.concat(dfs)\n",
    "        master_df.to_csv(os.path.join(PROJECT_PATH,f\"results_{phen_pair[0]}.csv\"),index=False)\n",
    "        print(os.path.join(PROJECT_PATH,f\"results_{phen_pair[0]}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_file_path)\n",
    "# # list(df[\"output_path\"][:10])\n",
    "# df[df[\"output_path\"] == \"/sci/nosnap/michall/roeizucker/covar_tests/results/_AC_batch_40_PC_i10_chr6\"][\"covariates\"][0]\n",
    "# # df = pd.read_csv(\"/sci/nosnap/michall/roeizucker/covar_tests/results/_AC_batch_40_PC_i10_chr6.PHENO1.glm.logistic\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0371c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = os.path.join(PROJECT_PATH,f\"results_{phen}.csv\")\n",
    "!head {val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3485948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "master_df.to_csv(os.path.join(PROJECT_PATH,\"results.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c47db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = os.path.join(PROJECT_PATH,\"output\")\n",
    "for filename in os.scandir(output_folder_path):\n",
    "    if filename.is_file():\n",
    "        with open(filename.path,\"r\") as file:\n",
    "            file_content = file.read()\n",
    "            if \"done!\" not in file_content and \"covar_testsmaster\" not in file_content and \"print(df.loc[butch_num * BATCH_LENGTH + curr_task])\" not in file_content:\n",
    "                print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df[\"#CHROM\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
