{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc7edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5b8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da0e7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "PHEN_PATH = \"/cs/labs/michall/roeizucker/non_caucasian_run_2/african_ukbb_dataset.csv\"\n",
    "GWAS_PATH = \"/cs/labs/michall/roeizucker/non_caucasian_run_2/GWAS\"\n",
    "PHENOTYPES = [\"J45_african\"]\n",
    "RESULT_SUFFIX = \"PHENO1.glm.logistic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0c32be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/cs/labs/michall/roeizucker/non_caucasian_run_2/GWAS_asian': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls {GWAS_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "790c772e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J45_asian\n",
      "how to run:\n",
      "sbatch --array=0-263 --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"/cs/labs/michall/roeizucker/non_caucasian_run_2/GWAS_asian/master.sh 0\"\n"
     ]
    }
   ],
   "source": [
    "# script body (will be transferred to another file)\n",
    "\n",
    "# script consts\n",
    "PHEN_START = 2\n",
    "VALUE_AT_END_OF_PHENOTYPES = 'const'\n",
    "PLINK_PATH = \"/cs/usr/nadavb/third_party/plink2\"\n",
    "BATCH_LENGTH = 250\n",
    "MAX_JOBS_BEFORE_SUBMITTING_NEW_ARRAY = 200\n",
    "\n",
    "# TODO: add verbous argument, and better explain the output\n",
    "def create_files(gwas_path,phen_path,phenotypes):\n",
    "    !mkdir {gwas_path}\n",
    "    !mkdir {gwas_path}/results\n",
    "    !mkdir {gwas_path}/phenotypes\n",
    "    !cp /cs/labs/michall/roeizucker/10krun/runs/0:11/GWAS_delete_me/covariates.txt {gwas_path}/covariates.txt\n",
    "    !cd {gwas_path}\n",
    "    dataset = pd.read_csv(phen_path)\n",
    "    for phenotype_col in phenotypes:\n",
    "        print(phenotype_col)\n",
    "        file_name = phenotype_col.lower().replace(' ', '_').replace('-', '_') + '.txt'\n",
    "        values = dataset[['eid', 'eid', phenotype_col]].dropna()\n",
    "        values.to_csv(os.path.join(f\"{gwas_path}/phenotypes\", file_name), \\\n",
    "            header = False, index = False, sep = '\\t')\n",
    "\n",
    "        # An array is created with all the values needed for running GWAS.\n",
    "# The array will be sorted in batches for better file accessing\n",
    "def create_the_data_file(phenotype_cols,gwas_path,data_file_path):\n",
    "    values = []\n",
    "    last_counter = 0\n",
    "    cur_phen_counter = 0\n",
    "    counter = 0\n",
    "    for phen in phenotype_cols:\n",
    "        base_path =  gwas_path\n",
    "        for j in range(1,23):\n",
    "            if os.path.exists(os.path.join(base_path ,f\"results/{phen.lower()}_chr{j}.PHENO1.glm.linear\")):\n",
    "                continue\n",
    "            # TODO: change location of plink files to be const\n",
    "            values.append([counter,os.path.join(base_path, \"phenotypes/\"+ phen.lower() + \".txt\"),\n",
    "                           os.path.join(base_path, f\"results/{phen.lower()}_chr{j}\"),\n",
    "                           f\"/cs/labs/michall/roeizucker/plink_results/reduced_snps2/small_ch{j}\"\n",
    "                           ,os.path.join(base_path ,\"covariates.txt\"),j])\n",
    "            counter+=1\n",
    "        cur_phen_counter+=1\n",
    "        if cur_phen_counter%BATCH_LENGTH == 0:\n",
    "            values[last_counter:counter] = sorted(values[last_counter:counter],key = lambda x:x[-1])\n",
    "            last_counter = counter\n",
    "    values[last_counter:counter] = sorted(values[last_counter:counter],key = lambda x:x[-1])\n",
    "    df = pd.DataFrame(values, columns=[\"unsorted_counter\",\"phenotype_path\",\"output_path\",\"partial_chromosome_file_path\", \"covariates\",\"chr\"])\n",
    "    df.to_csv(data_file_path)\n",
    "\n",
    "\n",
    "def write_mediator_script(mediator_script_path,data_file_path,gwas_path):\n",
    "    with open(mediator_script_path, \"w\") as mediator_file:\n",
    "        mediator_file.write(f'''import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "butch_num = int(sys.argv[1]) \n",
    "curr_task = int(sys.argv[2])\n",
    "BATCH_LENGTH = {BATCH_LENGTH}\n",
    "SKIP_POINT = {MAX_JOBS_BEFORE_SUBMITTING_NEW_ARRAY}\n",
    "PLINK_PATH = \"/cs/usr/nadavb/third_party/plink2\"\n",
    "\n",
    "data_file_path = \"{data_file_path}\"\n",
    "df = pd.read_csv(data_file_path)\n",
    "print(df.loc[butch_num * BATCH_LENGTH + curr_task])\n",
    "val = df.loc[butch_num * BATCH_LENGTH + curr_task]\n",
    "location = butch_num * BATCH_LENGTH + curr_task\n",
    "if curr_task == SKIP_POINT and location < 30500:\n",
    "    new_batch  = butch_num + 1\n",
    "    if not os.path.isfile(\"{gwas_path}_\" + str(new_batch) + \"_flag\"):\n",
    "        os.system(\"sbatch --array=0-\"+str(BATCH_LENGTH - 1)+\" --mem=12g -c10 --time=3-0 --killable --requeue --wrap=\\\\\"{gwas_path}master.sh \"+str(new_batch)+\"\\\\\"\")\n",
    "if location < 30500:\n",
    "    print(PLINK_PATH + \" --bed \" + df.loc[location].partial_chromosome_file_path + \".bed --bim \" + df.loc[location].partial_chromosome_file_path + \".bim --fam \"+df.loc[location].partial_chromosome_file_path + \".fam --pheno \" + df.loc[location].phenotype_path + \" --covar \" + df.loc[location].covariates + \"  --out  \" + df.loc[location].output_path + \" --1 --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads 10 --memory 10000\")\n",
    "    os.system(PLINK_PATH + \" --bed \" + df.loc[location].partial_chromosome_file_path + \".bed --bim \" + df.loc[location].partial_chromosome_file_path + \".bim --fam \"+df.loc[location].partial_chromosome_file_path + \".fam --pheno \" + df.loc[location].phenotype_path + \" --covar \" + df.loc[location].covariates + \"  --out  \" + df.loc[location].output_path + \" --1 --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads 10 --memory 10000\")\n",
    "    print(\"done!\")\n",
    "''')\n",
    "\n",
    "def write_master_script(master_script_path,mediator_script_path,gwas_path):\n",
    "    with open(master_script_path, \"w\") as master_file:\n",
    "        master_file.write(f'''\n",
    "FILE={gwas_path}_$1_flag\n",
    "if ! test \"$FILE\" \n",
    "then \n",
    "    touch {gwas_path}_$1_flag\n",
    "fi\n",
    "python {mediator_script_path} $1 $SLURM_ARRAY_TASK_ID\n",
    "''')\n",
    "    !chmod 744 {master_script_path}\n",
    "\n",
    "# set input \n",
    "# TODO: change so it is accepted as params\n",
    "phen_path = PHEN_PATH\n",
    "gwas_path = GWAS_PATH\n",
    "\n",
    "# do stuff\n",
    "phenotype_cols = list(pd.read_csv(PHEN_PATH))\n",
    "phenotype_cols = phenotype_cols[2:phenotype_cols.index(VALUE_AT_END_OF_PHENOTYPES)]\n",
    "if len (PHENOTYPES) > 0:\n",
    "    phenotype_cols = PHENOTYPES\n",
    "# TODO: chnage so names are consts\n",
    "data_file_path = os.path.join(gwas_path, \"data_file.csv\")\n",
    "mediator_script_path = os.path.join(gwas_path , \"mediator.py\")\n",
    "master_script_path = os.path.join(gwas_path , \"master.sh\")\n",
    "\n",
    "create_files(gwas_path,phen_path,phenotype_cols)\n",
    "create_the_data_file(phenotype_cols,gwas_path,data_file_path)\n",
    "write_mediator_script(mediator_script_path,data_file_path,gwas_path)\n",
    "write_master_script(master_script_path,mediator_script_path,gwas_path)\n",
    "\n",
    "# TODO: add output folder\n",
    "print(f'''how to run:\n",
    "sbatch --array=0-263 --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"{master_script_path} 0\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ce5358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cs/labs/michall/roeizucker/non_caucasian_run_2/GWAS_caucasian_reduced/master.sh'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# master_script_path = priority_gwas_dir + \"master.sh\"\n",
    "\n",
    "# (mediator_script_path,data_file_path,gwas_path)\n",
    "master_script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1521cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to run:\n",
      "sbatch --array=0-263 --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"/cs/labs/michall/roeizucker/non_caucasian_run_2/GWAS_caucasian_reduced/master.sh 0\"\n"
     ]
    }
   ],
   "source": [
    "print(f'''how to run:\n",
    "sbatch --array=0-263 --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"{master_script_path} 0\"''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fbfbb",
   "metadata": {},
   "source": [
    "## combines GWAS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71878eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cs/labs/michall/roeizucker/10krun/runs/84:95/GWAS/results/J45.csv\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "# path = \"/cs/labs/michall/roeizucker/10krun/runs/48:59/GWAS/results\"\n",
    "# os.chdir(path)\n",
    "path = os.path.join(GWAS_PATH,\"results\")\n",
    "# files = []\n",
    "# for file in glob.glob(\"*.glm.*\"):\n",
    "#     files.append(file)\n",
    "phens = PHENOTYPES\n",
    "for phen in phens:\n",
    "    dataframes = []\n",
    "    for j in range(1,23):\n",
    "#         change so logistic/liner is detrmined generically\n",
    "        file_name = os.path.join(path,f\"{phen}_chr{j}.{RESULT_SUFFIX}\")\n",
    "        df = pd.read_csv(file_name,sep=\"\\t\")\n",
    "        dataframes.append(df)\n",
    "#         print(df.head())\n",
    "    master_df = pd.concat(dataframes)\n",
    "    master_df.to_csv(f\"{os.path.join(path,phen)}.csv\",index=False)\n",
    "    print(f\"{os.path.join(path,phen)}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHENOTYPES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
