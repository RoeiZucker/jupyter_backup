{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654b867b-a336-4b3a-ab08-b4c443109b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas_plink import read_plink\n",
    "import pandas_plink as pdp\n",
    "from pandas_plink import get_data_folder\n",
    "import random\n",
    "import json\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69e1b4a-f93b-46fd-ac73-9154e7434f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variants randomly\n",
    "# select variants by rarity\n",
    "# use linear calculation\n",
    "# use non linear calculation\n",
    "# with/without PC\n",
    "# how rare should the phenotype be - like an existing one\n",
    "# create syntetic covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c841dc-da9a-464c-89a5-ae8e08096172",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENETICS_PATH = \"/sci/nosnap/michall/roeizucker/covar_tests/small_genetics\"\n",
    "COVARS_PATH = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK\"\n",
    "PLINK_PATH = \"/sci/nosnap/michall/roeizucker/plink2\"\n",
    "TEST_COVAR = \"covariates_sex_year_of_birth_AC_batch_40_PC.txt\"\n",
    "# TEST_CHROM = \"chr22_filtered_mafe-2_hwee-10_geno_02_random_001pct\"\n",
    "TEST_CHROM = \"chr22_filtered_mafe-2_hwee-10_geno_02_random_01pct\"\n",
    "PLINK_RESULT_PATH = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/results/chr22_very_reduced_simulation\"\n",
    "PLINK_RESULT_DIR = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/results/\"\n",
    "PHENOTYPE_FILE_RESULT_PATH = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/phenotypes/generated_phen.txt\"\n",
    "PERSON_BATCH_SIZE = 2000\n",
    "\n",
    "VERSION = \"multi_effect_score_0.3\"\n",
    "COVAR_DF_PREFIX = \"temp_covar_df\"\n",
    "INCLUDED_COVARS = [\"sex\",\"year_of_birth\",\"AC\",\"batch\"]\n",
    "AC_VALS = ['AC_stockport_pilot','AC_manchester','AC_oxford','AC_cardiff','AC_glasgow','AC_edinburgh','AC_stoke','AC_reading','AC_bury','AC_newcastle','AC_bristol','AC_barts','AC_nottingham','AC_sheffield','AC_liverpool','AC_middlesborough','AC_hounslow','AC_croydon','AC_birmingham','AC_swansea','AC_wrexham','AC_cheadle_revisit','AC_cheadle_imaging','AC_reading_imaging','AC_newcastle_imaging']\n",
    "BATCH_VALS = ['batch_Batch_b001','batch_Batch_b002','batch_Batch_b003','batch_Batch_b004','batch_Batch_b005','batch_Batch_b006','batch_Batch_b007','batch_Batch_b008','batch_Batch_b009','batch_Batch_b010','batch_Batch_b011','batch_Batch_b012','batch_Batch_b013','batch_Batch_b014','batch_Batch_b015','batch_Batch_b016','batch_Batch_b017','batch_Batch_b018','batch_Batch_b019','batch_Batch_b020','batch_Batch_b021','batch_Batch_b022','batch_Batch_b023','batch_Batch_b024','batch_Batch_b025','batch_Batch_b026','batch_Batch_b027','batch_Batch_b028','batch_Batch_b029','batch_Batch_b030','batch_Batch_b031','batch_Batch_b032','batch_Batch_b033','batch_Batch_b034','batch_Batch_b035','batch_Batch_b036','batch_Batch_b037','batch_Batch_b038','batch_Batch_b039','batch_Batch_b040','batch_Batch_b041','batch_Batch_b042','batch_Batch_b043','batch_Batch_b044','batch_Batch_b045','batch_Batch_b046','batch_Batch_b047','batch_Batch_b048','batch_Batch_b049','batch_Batch_b050','batch_Batch_b051','batch_Batch_b052','batch_Batch_b053','batch_Batch_b054','batch_Batch_b055','batch_Batch_b056','batch_Batch_b057','batch_Batch_b058','batch_Batch_b059','batch_Batch_b060','batch_Batch_b061','batch_Batch_b062','batch_Batch_b063','batch_Batch_b064','batch_Batch_b065','batch_Batch_b066','batch_Batch_b067','batch_Batch_b068','batch_Batch_b069','batch_Batch_b070','batch_Batch_b071','batch_Batch_b072','batch_Batch_b073','batch_Batch_b074','batch_Batch_b075','batch_Batch_b076','batch_Batch_b077','batch_Batch_b078','batch_Batch_b079','batch_Batch_b080','batch_Batch_b081','batch_Batch_b082','batch_Batch_b083','batch_Batch_b084','batch_Batch_b085','batch_Batch_b086','batch_Batch_b087','batch_Batch_b088','batch_Batch_b089','batch_Batch_b090','batch_Batch_b091','batch_Batch_b092','batch_Batch_b093','batch_Batch_b094','batch_Batch_b095','batch_UKBiLEVEAX_b1','batch_UKBiLEVEAX_b10','batch_UKBiLEVEAX_b11','batch_UKBiLEVEAX_b3','batch_UKBiLEVEAX_b4','batch_UKBiLEVEAX_b5','batch_UKBiLEVEAX_b6','batch_UKBiLEVEAX_b7','batch_UKBiLEVEAX_b8','batch_UKBiLEVEAX_b9']\n",
    "ALL_COVARS = INCLUDED_COVARS[:-2] + AC_VALS + BATCH_VALS\n",
    "NUM_PC = 40\n",
    "for i in range(NUM_PC):\n",
    "    ALL_COVARS.append(f\"PC{i+1}\")\n",
    "YOB_SUBTRACTOR = 1880\n",
    "YOB_DEVIDOR = 100\n",
    "\n",
    "\n",
    "# phenotype generation constants\n",
    "TARGET_VARIANCE = 1\n",
    "DISEASE_PREVELANCE = 0.02\n",
    "PHENOTYPE_DIR_RESULT_PATH = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/phenotypes/\"\n",
    "INCLUDE_COVAR = True\n",
    "AC_EFFECT_SCORE = 1\n",
    "BATCH_EFFECT_SCORE = 1\n",
    "\n",
    "\n",
    "# do a logistic regression between PC and phenotype, to show that snps \n",
    "# do not effect through population structure\n",
    "SEX_EFFECT = 3\n",
    "YOB_EFFECT = 1\n",
    "PC_EFFECT_MAX = 0.3\n",
    "\n",
    "# COVAR_GENETIC_EFFECT_RATIO = 2\n",
    "HERETEBILITY = 0.2\n",
    "COVAR_EFFECT = 0.5\n",
    "\n",
    "\n",
    "HERETABILITY_SCORES = [0,0.1,0.2,0.3,0.5,0.7]\n",
    "COVARIATE_SCORES = [0,0.1,0.2,0.3,0.5,0.7]\n",
    "# TODO change the name and function to heretibility to heretibility\n",
    "# heretibility is the variance of the genetics / (var genetcis + var covar)\n",
    "\n",
    "AC_EFFECT = [AC_EFFECT_SCORE]*len(AC_VALS)\n",
    "BATCH_EFFECT = [BATCH_EFFECT_SCORE]*len(BATCH_VALS)\n",
    "# add PC stratagy\n",
    "PC_EFFECT = list(np.arange(PC_EFFECT_MAX,0,-PC_EFFECT_MAX/NUM_PC))\n",
    "COVAR_EFFECTS = [SEX_EFFECT,YOB_EFFECT] + AC_EFFECT + BATCH_EFFECT + PC_EFFECT\n",
    "\n",
    "# TODO: change to work as beta.\n",
    "# create a function that accepts a vector of Betas and a flag if its binary/continues and add an option for covariates\n",
    "# If its binary, add prevelance considiration\n",
    "# for a person J the score for J is the sum over all betas of SNPS * the number of alleles. \n",
    "# add a noise so that the variance of phenotype will be 1 (adding noise using 1-sigma) call this Yj\n",
    "# to do so calculate overall variance after simulation, and add a noise with 1- the variance (make sure that the genetic + covar variance is below 1)\n",
    "# in continues state, use Yj as phenotype (maybe mul by a constant)\n",
    "# in binary state the same, need to do a logit (sigmuid and then threashold or just threshold) transformation. detarmine the threshold so that X% of the population are sick\n",
    "# another way, in the binary state instead of noise can do a bernuli on the result of the sigmuid (a value between 0 and 1)\n",
    "# the covariats can be treated the same way the betas are used\n",
    "# read about genetic architucture, compare covariates and betas effect.\n",
    "# the aggregative effect of snps should be larger, but the effect of a single snp should be smaller.\n",
    "\n",
    "# look at GWAS catalog, use a table from there for a specific disease and take their betas (find out how to calculate beta from OR)\n",
    "\n",
    "# variant parameter\n",
    "NUMBER_OF_MAJOR_VARIANTS = 150\n",
    "NUMBER_OF_MEDIUM_VARIANTS = 400\n",
    "NUMBER_OF_LESSER_VARIANTS = 700\n",
    "\n",
    "MAJOR_VARIANT_EFFECT = 0.05\n",
    "MEDIUM_VARIANT_EFFECT = 0.015\n",
    "LESSER_VARIANT_EFFECT = 0.005\n",
    "\n",
    "# change to betas\n",
    "MAJOR_VARIANT_DELTA = 1\n",
    "MEDIUM_VARIANT_DELTA = 0.3\n",
    "LESSER_VARIANT_DELTA = 0.01\n",
    "\n",
    "\n",
    "# TODO: implement memory and threads in script\n",
    "MEMORY = 10000\n",
    "THREADS = 10\n",
    "\n",
    "COVAR_GROUPS = [\n",
    "    \"covariates_year_of_birth_0_PC\",\n",
    "    \"covariates_sex_0_PC\",\n",
    "    \"covariates_sex_year_of_birth_0_PC\",\n",
    "    \"covariates_5_PC\",\n",
    "    \"covariates_sex_year_of_birth_40_PC\",\n",
    "    \"covariates_sex_year_of_birth_batch_40_PC\",\n",
    "    \"covariates_sex_year_of_birth_AC_40_PC\",\n",
    "    \"covariates_sex_year_of_birth_AC_batch_40_PC\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fe45e6-b4a9-4475-b971-8c7bef13619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [04:00<00:00, 80.10s/it]\n"
     ]
    }
   ],
   "source": [
    "G = pdp.read_plink1_bin(os.path.join(GENETICS_PATH,TEST_CHROM) + \".bed\",os.path.join(GENETICS_PATH,TEST_CHROM) + \".bim\",os.path.join(GENETICS_PATH,TEST_CHROM) + \".fam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe83dc-76f8-4b18-b117-58e9ca781049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ca41c-4a52-46b1-825d-859008960d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc2bd1-c282-40c8-a07c-72c4fe633055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43197c6f-198e-4a08-bf68-c6e30ba544ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = G.to_dataframe()\n",
    "# df = df.reset_index()\n",
    "# covar_df = pd.read_csv(os.path.join(COVARS_PATH,TEST_COVAR),sep=\"\\t\",header=None)\n",
    "# covar_df = covar_df.set_axis([\"iid\",\"fid\"] + ALL_COVARS, axis=1)\n",
    "# legal_iid = set(covar_df[\"iid\"].astype(str))\n",
    "# df = df[df[\"iid\"].isin(legal_iid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d8d3ea-bfb8-4a63-b28e-dd83d8cdcf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e920e5ad-6a42-45b4-90ca-945c45ec5081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e9edea-0cf8-4163-b1b4-6eb72777b23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587cbdb0-41c3-4bef-9f21-a7e76f7bca55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7216d5-09df-48b9-868a-26861b1a576f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2957b44-0e41-456f-ae5b-4c08e5ae3bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c38b1a-5269-4a0f-88d6-090719f6830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1665d573-eb80-44a6-b834-f06c0de79665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    }
   ],
   "source": [
    "print(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d1f310b-6691-414b-bb61-9e38f3ef816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covar_df = covar_df.set_index(\"iid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc5213db-24b9-463b-b47e-e93e12d83bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_variants(df):\n",
    "    unique_variants = list(df[\"variant\"].unique())\n",
    "    random.shuffle(unique_variants)\n",
    "    return unique_variants\n",
    "\n",
    "def get_variant_groups(unique_variants):\n",
    "    major_variants = set(unique_variants[0:NUMBER_OF_MAJOR_VARIANTS])\n",
    "    medium_variants = set(unique_variants[NUMBER_OF_MAJOR_VARIANTS:NUMBER_OF_MAJOR_VARIANTS+NUMBER_OF_MEDIUM_VARIANTS])\n",
    "    lesser_variants = set(unique_variants[NUMBER_OF_MAJOR_VARIANTS+NUMBER_OF_MEDIUM_VARIANTS:NUMBER_OF_MAJOR_VARIANTS+NUMBER_OF_MEDIUM_VARIANTS+NUMBER_OF_LESSER_VARIANTS])\n",
    "    return major_variants, medium_variants, lesser_variants\n",
    "\n",
    "def create_effect_dict(included_variants,major_variants,medium_variants,lesser_variants):\n",
    "    effect_dict = {}\n",
    "    for var in included_variants:\n",
    "        if var in major_variants:\n",
    "            effect_dict[var] = MAJOR_VARIANT_DELTA\n",
    "            continue\n",
    "        if var in medium_variants:\n",
    "            effect_dict[var] = MEDIUM_VARIANT_DELTA\n",
    "            continue\n",
    "        effect_dict[var] = LESSER_VARIANT_DELTA\n",
    "    return effect_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd8c7aae-908e-4271-ac90-07b68a7f0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_df = pd.read_csv(os.path.join(COVARS_PATH,TEST_COVAR),sep=\"\\t\",header=None)\n",
    "covar_df = covar_df.set_axis([\"iid\",\"fid\"] + ALL_COVARS, axis=1)\n",
    "legal_iid = set(covar_df[\"iid\"].astype(str))\n",
    "samples_list = G.sample.to_series()\n",
    "test_ids = list(samples_list[:1])\n",
    "G_subset = G.sel(sample=test_ids)\n",
    "sample_df = G_subset.to_dataframe()\n",
    "sample_df = sample_df.reset_index()\n",
    "\n",
    "\n",
    "unique_variants = get_unique_variants(sample_df)\n",
    "major_variants, medium_variants, lesser_variants = get_variant_groups(unique_variants)\n",
    "included_variants = major_variants.union(medium_variants).union(lesser_variants)\n",
    "covar_df['year_of_birth'] = (covar_df['year_of_birth'] - covar_df['year_of_birth'].mean()) / covar_df['year_of_birth'].std()\n",
    "effect_dict = create_effect_dict(included_variants,major_variants,medium_variants,lesser_variants)\n",
    "covar_df[\"covar_effects_chance\"] = None\n",
    "covar_df[\"genetic_chance\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbc381-22d1-4f0c-a0bc-5b38d1afdcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddedbd-5302-4ed4-a4cc-05360105e292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c85cc620-7b2e-46d8-bab7-37605602779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486000 99 %\n"
     ]
    }
   ],
   "source": [
    "def get_variant_specific_df(G_subset):\n",
    "    df = G_subset.to_dataframe()\n",
    "    df = df.reset_index()\n",
    "    df = df[df[\"variant\"].isin(included_variants)]\n",
    "    return df\n",
    "\n",
    "def get_genotype_dict(df):\n",
    "    genotype_dict = df[[\"iid\",\"variant\",\"genotype\"]].set_index([\"iid\",\"variant\"]).to_dict(orient=\"index\")\n",
    "    for key in genotype_dict.keys():\n",
    "        genotype_dict[key] = genotype_dict[key][\"genotype\"]\n",
    "\n",
    "\n",
    "for i in range(0,len(samples_list),PERSON_BATCH_SIZE):\n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(i,int( 100*(i /len(samples_list))),\"%\")\n",
    "\n",
    "    start = i\n",
    "    end = i+PERSON_BATCH_SIZE\n",
    "    test_ids = list(samples_list[start:end])\n",
    "    G_subset = G.sel(sample=test_ids)\n",
    "    df = get_variant_specific_df(G_subset)\n",
    "    genotype_dict = get_genotype_dict(df)\n",
    "    # calculate effect for each variant for each person TODO: extract to function\n",
    "    df[\"effect\"] = df[\"variant\"].map(effect_dict)\n",
    "    df[\"effect\"] = df[\"effect\"]*df[\"genotype\"]\n",
    "    df = df.reset_index()\n",
    "\n",
    "    covar_df[\"covar_effects_chance\"] = ((np.array(covar_df[covar_df.columns[2:-2]]) @ (np.array(COVAR_EFFECTS)))) \n",
    "    \n",
    "    # TODO: change name\n",
    "    disease_chance_dict = (1 - df.groupby(\"iid\")[\"effect\"].sum()).to_dict()\n",
    "    # disease_chance_dict\n",
    "    # TODO: change name, this is not a chance, but a result\n",
    "    covar_df[\"genetic_chance\"] = covar_df[\"iid\"].astype(str).map(disease_chance_dict).fillna(covar_df[\"genetic_chance\"])\n",
    "    # adjust so genetic effect and covar effect match the requested\n",
    "\n",
    "\n",
    "# afterwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "469747b7-27c9-461f-aa86-448058e94a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC effect 6.149999999999994\n",
      "other covars effect 6\n",
      "PC relative effect in PC 0.5061728395061725\n"
     ]
    }
   ],
   "source": [
    "# [SEX_EFFECT,YOB_EFFECT] + AC_EFFECT + BATCH_EFFECT + PC_EFFECT\n",
    "pc_total_effect = sum(PC_EFFECT)\n",
    "other_total_effect = sum([SEX_EFFECT,YOB_EFFECT] +[AC_EFFECT_SCORE,BATCH_EFFECT_SCORE])\n",
    "print(\"PC effect\",pc_total_effect)\n",
    "print(\"other covars effect\",other_total_effect)\n",
    "print(\"PC relative effect in PC\",pc_total_effect / (pc_total_effect+other_total_effect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b757ec70-1c2a-48a8-a00c-7d86e15f64e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted pc relative effect in PC 0.8039899487383934\n"
     ]
    }
   ],
   "source": [
    "# ((np.array(covar_df[covar_df.columns[2:-2]]) @ (np.array(COVAR_EFFECTS))))\n",
    "# COVAR_EFFECTS = [SEX_EFFECT,YOB_EFFECT] + AC_EFFECT + BATCH_EFFECT + PC_EFFECT\n",
    "abs_array = np.abs(np.array(covar_df[covar_df.columns[2:-2]]))\n",
    "abs_scores =  abs_array@np.array(COVAR_EFFECTS)\n",
    "covar_only_effects = [0,0] + [0]*(len(AC_EFFECT) + len(BATCH_EFFECT)) + PC_EFFECT\n",
    "covar_only_scores = abs_array@np.array(covar_only_effects)\n",
    "pc_only_scores = covar_only_scores/abs_scores\n",
    "print(\"weighted pc relative effect in PC\",np.mean(pc_only_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d7dbb00-b2c0-454a-8bc5-cbb6e07ca23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print create JSON with parameters\n",
    "parameters_to_save_for_version = {\n",
    "    \"VERSION\":VERSION,\n",
    "    \"TARGET_VARIANCE\":TARGET_VARIANCE,\n",
    "    \"DISEASE_PREVELANCE\":DISEASE_PREVELANCE,\n",
    "    \"NUMBER_OF_MAJOR_VARIANTS\":NUMBER_OF_MAJOR_VARIANTS,\n",
    "    \"NUMBER_OF_MEDIUM_VARIANTS\":NUMBER_OF_MEDIUM_VARIANTS,\n",
    "    \"NUMBER_OF_LESSER_VARIANTS\":NUMBER_OF_LESSER_VARIANTS,\n",
    "    \"MAJOR_VARIANT_DELTA\":MAJOR_VARIANT_DELTA,\n",
    "    \"MEDIUM_VARIANT_DELTA\":MEDIUM_VARIANT_DELTA\n",
    "}\n",
    "if INCLUDE_COVAR:\n",
    "\n",
    "    parameters_to_save_for_version[\"AC_EFFECT_SCORE\"] = AC_EFFECT_SCORE\n",
    "    parameters_to_save_for_version[\"BATCH_EFFECT_SCORE\"] = BATCH_EFFECT_SCORE\n",
    "    parameters_to_save_for_version[\"SEX_EFFECT\"] = SEX_EFFECT\n",
    "    parameters_to_save_for_version[\"YOB_EFFECT\"] = YOB_EFFECT\n",
    "    parameters_to_save_for_version[\"PC_EFFECT_MAX\"] = PC_EFFECT_MAX\n",
    "json_file_name = VERSION + \"_parameters\" + \".json\"\n",
    "if os.path.exists(json_file_name):\n",
    "    raise Exception(\"Version file exists\")\n",
    "with open(json_file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump(parameters_to_save_for_version, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87228e90-0955-4362-abb5-78e9f110f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0.1\n",
      "0 0.2\n",
      "0 0.3\n",
      "0 0.5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m temp_cov_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisease_indicator\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     22\u001b[0m     temp_cov_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisease_chance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m quantile\n\u001b[1;32m     23\u001b[0m )\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# temp_cov_df.dropna()\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtemp_cov_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCOVAR_DF_PREFIX\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_v=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mVERSION\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_her=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mher_score\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_cov=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcov_score\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Note: self.encoding is irrelevant here\u001b[39;49;00m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcsvlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/io/common.py:157\u001b[0m, in \u001b[0;36mIOHandles.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    153\u001b[0m     exc_type: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mBaseException\u001b[39;00m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    154\u001b[0m     exc_value: \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m     traceback: TracebackType \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    156\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sci/nosnap/michall/roeizucker/new_python_env/lib/python3.11/site-packages/pandas/io/common.py:144\u001b[0m, in \u001b[0;36mIOHandles.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreated_handles\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreated_handles:\n\u001b[0;32m--> 144\u001b[0m     handle\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreated_handles \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# TODO: add creation of multiple phenotype files\n",
    "for her_score in HERETABILITY_SCORES:\n",
    "    for cov_score in COVARIATE_SCORES:\n",
    "        print(her_score,cov_score)\n",
    "        temp_cov_df = covar_df.copy()\n",
    "        gene_var = ((temp_cov_df[\"genetic_chance\"]).var())\n",
    "        covar_var = (temp_cov_df[\"covar_effects_chance\"].var())\n",
    "        genetic_factor = np.sqrt(her_score/gene_var)\n",
    "        covar_factor = np.sqrt(cov_score/covar_var)\n",
    "        temp_cov_df[\"genetic_chance\"] = temp_cov_df[\"genetic_chance\"] * genetic_factor\n",
    "        temp_cov_df[\"covar_effects_chance\"] = temp_cov_df[\"covar_effects_chance\"] * covar_factor\n",
    "        temp_cov_df[\"disease_chance\"] = temp_cov_df[\"genetic_chance\"] + temp_cov_df[\"covar_effects_chance\"]\n",
    "        added_variance = TARGET_VARIANCE -temp_cov_df[\"disease_chance\"].var()\n",
    "\n",
    "        mu, sigma = 0, added_variance # mean and standard deviation\n",
    "        noise = np.random.normal(mu, sigma**0.5, len(temp_cov_df))\n",
    "        temp_cov_df[\"disease_chance\"] = temp_cov_df[\"disease_chance\"] + noise\n",
    "        # temp_cov_df[\"disease_chance\"].var()\n",
    "        quantile = (temp_cov_df[[\"disease_chance\"]].quantile(1 - DISEASE_PREVELANCE, method=\"table\", interpolation=\"nearest\")[\"disease_chance\"])\n",
    "        \n",
    "        temp_cov_df['disease_indicator'] = (\n",
    "            temp_cov_df['disease_chance'] > quantile\n",
    "        ).astype(int).astype(float)\n",
    "        # temp_cov_df.dropna()\n",
    "        temp_cov_df.to_csv(f\"{COVAR_DF_PREFIX}_v={VERSION}_her={her_score}_cov={cov_score}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d5ecd-cf33-41de-98ff-010c509c64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(False)\n",
    "# # TODO: change so variants are selected from all over the genom, and by prevelance \n",
    "# major_variants = set(unique_variants[0:NUMBER_OF_MAJOR_VARIANTS])\n",
    "# medium_variants = set(unique_variants[NUMBER_OF_MAJOR_VARIANTS:NUMBER_OF_MAJOR_VARIANTS+NUMBER_OF_MEDIUM_VARIANTS])\n",
    "# lesser_variants = set(unique_variants[NUMBER_OF_MAJOR_VARIANTS+NUMBER_OF_MEDIUM_VARIANTS:NUMBER_OF_MAJOR_VARIANTS+NUMBER_OF_MEDIUM_VARIANTS+NUMBER_OF_LESSER_VARIANTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3980f-2c5a-4a44-898a-dabe0ba51735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# included_variants = major_variants.union(medium_variants).union(lesser_variants)\n",
    "# # TODO: add protective variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34da0a-1eac-4985-b0f8-95fc1d269a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df[\"variant\"].isin(included_variants)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bfdbfb-c626-4f67-b262-2c7cf5fe4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genotype_dict = df[[\"iid\",\"variant\",\"genotype\"]].set_index([\"iid\",\"variant\"]).to_dict(orient=\"index\")\n",
    "# for key in genotype_dict.keys():\n",
    "#     genotype_dict[key] = genotype_dict[key][\"genotype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01885c-6ca8-4e18-98a5-fb982cccc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_dict = {}\n",
    "for var in included_variants:\n",
    "    if var in major_variants:\n",
    "        effect_dict[var] = MAJOR_VARIANT_DELTA\n",
    "        continue\n",
    "    if var in medium_variants:\n",
    "        effect_dict[var] = MEDIUM_VARIANT_DELTA\n",
    "        continue\n",
    "    effect_dict[var] = LESSER_VARIANT_DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd6380-2e45-4a55-92a7-073acf2a3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "df[\"effect\"] = df[\"variant\"].map(effect_dict)\n",
    "# df[\"effect\"] = df[\"effect\"]**df[\"genotype\"]\n",
    "\n",
    "# Delta form\n",
    "df[\"effect\"] = df[\"effect\"]*df[\"genotype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476bf0fb-59b8-49d9-8e6c-f242f55fbd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e812c4a-c423-466d-a2de-749775f02ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: change so that the variance is for the phenotype_scroe\n",
    "# added_variance = TARGET_VARIANCE -df[\"effect\"].var()\n",
    "# mu, sigma = 0, added_variance # mean and standard deviation\n",
    "# noise = np.random.normal(mu, sigma**0.5, len(df))\n",
    "# df[\"fixed_effect\"] = df[\"effect\"] + noise\n",
    "# df[\"fixed_effect\"].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df82ea-6765-4fe1-935e-18bb7d03fc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab98a1-06a9-45ef-a453-dea3ae25185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "covar_df['year_of_birth'] = (covar_df['year_of_birth'] - covar_df['year_of_birth'].mean()) / covar_df['year_of_birth'].std()\n",
    "covar_df[\"year_of_birth\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0985a-9447-4e09-8d58-2597b191c3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533165b3-75c0-4728-9864-3d7ba471d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_df[\"covar_effects_chance\"] = ((np.array(covar_df[covar_df.columns[2:]]) @ (np.array(COVAR_EFFECTS)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfedff9-ac04-4438-b782-63853eadf0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f73e6-b98f-4d6c-82fb-fb3d3e2125bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change name\n",
    "disease_chance_dict = (1 - df.groupby(\"iid\")[\"effect\"].sum()).to_dict()\n",
    "# disease_chance_dict\n",
    "# TODO: change name, this is not a chance, but a result\n",
    "covar_df[\"genetic_chance\"] = covar_df[\"iid\"].astype(str).map(disease_chance_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1548c-62dc-42c8-888a-98a0eb0b38ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af2829-94fd-4151-8beb-7e4338587227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERETEBILITY = var(ax) = a**2*var(x)\n",
    "# HERETEBILITY = a**2*var(x)\n",
    "# a**2 = HERETEBILITY/var(x)\n",
    "# a = sqrt(HERETEBILITY/var(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd380c-af51-49cf-b7aa-a6eb21ce95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust so genetic effect and covar effect match the requested\n",
    "gene_var = ((covar_df[\"genetic_chance\"]).var())\n",
    "covar_var = (covar_df[\"covar_effects_chance\"].var())\n",
    "genetic_factor = np.sqrt(HERETEBILITY/gene_var)\n",
    "covar_factor = np.sqrt(COVAR_EFFECT/covar_var)\n",
    "# x = COVAR_GENETIC_EFFECT_RATIO*covar_sum/gene_sum\n",
    "# covar_df[\"genetic_chance\"] = covar_df[\"genetic_chance\"] * x\n",
    "covar_df[\"genetic_chance\"] = covar_df[\"genetic_chance\"] * genetic_factor\n",
    "covar_df[\"covar_effects_chance\"] = covar_df[\"covar_effects_chance\"] * covar_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60173ab8-5ddb-48e2-82f9-e2264c251fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_df[\"disease_chance\"] = covar_df[\"genetic_chance\"] + covar_df[\"covar_effects_chance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1f4e6-1041-400d-9211-ba615d9240af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change so that the variance is for the phenotype_scroe\n",
    "added_variance = TARGET_VARIANCE -covar_df[\"disease_chance\"].var()\n",
    "\n",
    "mu, sigma = 0, added_variance # mean and standard deviation\n",
    "noise = np.random.normal(mu, sigma**0.5, len(covar_df))\n",
    "covar_df[\"disease_chance\"] = covar_df[\"disease_chance\"] + noise\n",
    "covar_df[\"disease_chance\"].var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7540a820-d9b8-455d-b399-95538227bc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4adc02-32b6-4caa-9300-cf47cc83f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = (covar_df[[\"disease_chance\"]].quantile(1 - DISEASE_PREVELANCE, method=\"table\", interpolation=\"nearest\")[\"disease_chance\"])\n",
    "covar_df['disease_indicator'] = (\n",
    "    covar_df['disease_chance'] > quantile\n",
    ").astype(int).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72c0b0-d339-4eb1-ad34-d22d99bcfbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# randomly select variants instead of first 100\n",
    "# multiple phenotypes with different heretability/covar/random effects\n",
    "#     for each phenotype, run on each covar file that appeard in the original study\n",
    "# next step - use snp from catalog\n",
    "# when evaluating, finding something close to causal, is not a mistake, should be treated as true positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1451b-1357-416f-8507-d5a1cc0deff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AC_EFFECT_SCORE = 1\n",
    "# BATCH_EFFECT_SCORE = 1\n",
    "# SEX_EFFECT = 3\n",
    "# YOB_EFFECT = 1\n",
    "# PC_EFFECT_MAX = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073bc88-a293-40d3-859c-4892ed5b1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phenotype_file_result_name = (\n",
    "#     f\"generated_pehn_result_target_var={TARGET_VARIANCE}_target_prev={DISEASE_PREVELANCE}_\" + \n",
    "#     f\"major_n={NUMBER_OF_MAJOR_VARIANTS}_med_n={NUMBER_OF_MEDIUM_VARIANTS}_less__m={NUMBER_OF_LESSER_VARIANTS}_\" +\n",
    "#     f\"major_d={MAJOR_VARIANT_DELTA}_med_d={MEDIUM_VARIANT_DELTA}_less_d={LESSER_VARIANT_DELTA}_\" \n",
    "#     f\"heretability={HERETEBILITY}_covar_effect={COVAR_EFFECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed735819-4622-43f8-8cf3-efddeae1c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_file_result_name = (\n",
    "    f\"generated_pehn_result_ver={VERSION}_target_var={TARGET_VARIANCE}_target_prev={DISEASE_PREVELANCE}_\" + \n",
    "    f\"major_n={NUMBER_OF_MAJOR_VARIANTS}_med_n={NUMBER_OF_MEDIUM_VARIANTS}_less__m={NUMBER_OF_LESSER_VARIANTS}_\" +\n",
    "    f\"major_d={MAJOR_VARIANT_DELTA}_med_d={MEDIUM_VARIANT_DELTA}_less_d={LESSER_VARIANT_DELTA}_\" \n",
    "    f\"heretability={HERETEBILITY}_covar_effect={COVAR_EFFECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883fda19-9480-40a3-b3a7-56a9c25d1de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_file_result_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720647a-fc13-42df-b2da-b307cd0d1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "COVAR_EFFECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723ee65-f041-417f-8918-1b9978aeeb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if INCLUDE_COVAR:\n",
    "    phenotype_file_result_name+= (\n",
    "        f\"_ac={AC_EFFECT_SCORE}_batch={BATCH_EFFECT_SCORE}_sex={SEX_EFFECT}_yob={YOB_EFFECT}_pc_max={PC_EFFECT_MAX}\"\n",
    "    )\n",
    "\n",
    "phenotype_file_result_name = phenotype_file_result_name+\".txt\"\n",
    "phenotype_file_path = os.path.join(PHENOTYPE_DIR_RESULT_PATH,phenotype_file_result_name)\n",
    "covar_df[[\"iid\",\"fid\",\"disease_indicator\"]].to_csv(phenotype_file_path,index=False,header=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0cd516-b024-407a-a9ec-87dabf9a243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_file_result_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361aafe-3c85-4e9f-8128-ae959dae372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_path = os.path.join(GENETICS_PATH,TEST_CHROM)\n",
    "result_path = os.path.join(PLINK_RESULT_DIR,phenotype_file_result_name.replace(\".txt\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d4673-0e48-4ba0-b04e-5e419b3674a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "command =f\"{PLINK_PATH} --bed {chrom_path}.bed --bim {chrom_path}.bim --fam {chrom_path}.fam --pheno {phenotype_file_path} --covar {os.path.join(COVARS_PATH,TEST_COVAR)}  --out  {result_path} --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads 30 --memory 30000 --1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8c6d4-02b2-4222-98d3-27188aa60cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecda68e-f158-4c64-8bfa-bc5433e93dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = set(covar_df[\"fid\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db49326-fcb1-4bb3-9898-5600339f0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_df[reset_df[\"sample\"].isin(participants)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb473ac1-352a-4dbd-b276-0b472b942cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# included_variants = major_variants.union(medium_variants).union(lesser_variants)\n",
    "major_vars = list(df[df[\"variant\"].isin(major_variants)][\"snp\"].unique())\n",
    "med_vars = list(df[df[\"variant\"].isin(medium_variants)][\"snp\"].unique())\n",
    "lesser_vars = list(df[df[\"variant\"].isin(lesser_variants)][\"snp\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc8984-b4b7-4db0-b54a-3214b964139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_dict = {}\n",
    "variant_dict[\"major_vars\"] = major_vars\n",
    "variant_dict[\"med_vars\"] = med_vars\n",
    "variant_dict[\"lesser_vars\"] = lesser_vars\n",
    "json_file_name = phenotype_file_result_name.replace(\".txt\",\"\") + \"variants.json\"\n",
    "with open(json_file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump(variant_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e5dc7-1093-4078-acde-9bf66416f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(major_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e90e42-4891-4dc5-b75a-d95427d99dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(covar_df[covar_df.columns[2:-2]])[0]\n",
    "# actual code for mltiple\n",
    "for covar_type in COVAR_GROUPS:\n",
    "    covar_file = os.path.join(COVARS_PATH,covar_type + \".txt\")\n",
    "    result_path = os.path.join(PLINK_RESULT_DIR,phenotype_file_result_name.replace(\".txt\",covar_type))\n",
    "    command =f\"{PLINK_PATH} --bed {chrom_path}.bed --bim {chrom_path}.bim --fam {chrom_path}.fam --pheno {phenotype_file_path} --covar {covar_file}  --out  {result_path} --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads 10 --memory 10000 --1\"\n",
    "    # print(command)\n",
    "    print(f'sbatch --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"{command}\"')\n",
    "command =f\"{PLINK_PATH} --bed {chrom_path}.bed --bim {chrom_path}.bim --fam {chrom_path}.fam --pheno {phenotype_file_path} --out  {result_path} --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads 10 --memory 10000 --1\"\n",
    "# print(command)\n",
    "result_path = os.path.join(PLINK_RESULT_DIR,phenotype_file_result_name.replace(\".txt\",\"_no_covar\"))\n",
    "print(f'sbatch --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"{command}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b13cc-4d8f-4178-aebd-794f0817209b",
   "metadata": {},
   "source": [
    "## GWAS simulation visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b478a4e-6009-40a2-ac78-901a9cde73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PVAL_THRESHOLD = 5*10**-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e7c72-268b-4715-9be3-798b32575fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_name = phenotype_file_result_name.replace(\".txt\",\"\") + \"variants.json\"\n",
    "with open(json_file_name) as json_file:\n",
    "        variant_data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3cc716-8589-46bf-938b-8aa8e29221da",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f54b753-3ba0-460f-a49a-8439e14bf43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for covar_type in COVAR_GROUPS:\n",
    "    try:\n",
    "        covar_file = os.path.join(COVARS_PATH,covar_type + \".txt\")\n",
    "        result_path = os.path.join(PLINK_RESULT_DIR,phenotype_file_result_name.replace(\".txt\",covar_type) + \".PHENO1.glm.logistic.hybrid\")\n",
    "        df = pd.read_csv(result_path,sep=\"\\t\")\n",
    "        df = df[df[\"P\"] < PVAL_THRESHOLD]\n",
    "        variants = set(df[\"ID\"])\n",
    "        found_major = variants.intersection( variant_data[\"major_vars\"])\n",
    "        found_medium = variants.intersection( variant_data[\"med_vars\"])\n",
    "        found_lesser = variants.intersection( variant_data[\"lesser_vars\"])\n",
    "        print(covar_type)\n",
    "        print(\"found_major\",len(found_major),\"/\",len(variant_data[\"major_vars\"]))\n",
    "        print(\"found_medium\",len(found_medium),\"/\",len(variant_data[\"med_vars\"]))\n",
    "        print(\"found_lesser\",len(found_lesser),\"/\",len(variant_data[\"lesser_vars\"]))\n",
    "        print(\"found_overall\", len(variants))\n",
    "        print(\"found_extra\",len(variants - found_major.union(found_medium).union(found_lesser)))\n",
    "        \n",
    "        # print(variants)\n",
    "    except OSError as exc:\n",
    "        print(covar_file,\"failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abc003-fdd0-4cef-91df-db7ee4851ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
