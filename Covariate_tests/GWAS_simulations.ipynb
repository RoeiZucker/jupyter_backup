{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654b867b-a336-4b3a-ab08-b4c443109b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas_plink import read_plink\n",
    "import pandas_plink as pdp\n",
    "from pandas_plink import get_data_folder\n",
    "import random\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70db5f3-731b-4086-b385-c38ad3b55a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269113d-2cbc-4303-be8f-d63a267d7db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69e1b4a-f93b-46fd-ac73-9154e7434f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select variants randomly\n",
    "# select variants by rarity\n",
    "# use linear calculation\n",
    "# use non linear calculation\n",
    "# with/without PC\n",
    "# how rare should the phenotype be - like an existing one\n",
    "# create syntetic covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6c841dc-da9a-464c-89a5-ae8e08096172",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENETICS_PATH = \"/sci/archive/michall/roeizucker/small_genetics\"\n",
    "COVARS_PATH = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK\"\n",
    "PLINK_PATH = \"/sci/nosnap/michall/roeizucker/plink2\"\n",
    "TEST_COVAR = \"covariates_sex_year_of_birth_AC_batch_40_PC.txt\"\n",
    "# TEST_CHROM = \"/sci/archive/michall/roeizucker/small_genetics/allchr_thin_12\"\n",
    "TEST_CHROM = \"allchr_thin_fml\"\n",
    "CHROM_PREFIX = \"chr\"\n",
    "CHROM_SUFFIX = \"_thin00005\"\n",
    "PLINK_RESULT_PATH = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/results/chr22_very_reduced_simulation\"\n",
    "PLINK_RESULT_DIR = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/results/\"\n",
    "PHENOTYPE_FILE_RESULT_PATH = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/phenotypes/generated_phen.txt\"\n",
    "PERSON_BATCH_SIZE = 2000\n",
    "VERBOSE = False\n",
    "\n",
    "FILE_ENDING = \"PHENO1.glm.linear\"\n",
    "\n",
    "VERSION = \"multi_effect_score_0.7\"\n",
    "COVAR_DF_PREFIX = \"temp_covar_df\"\n",
    "INCLUDED_COVARS = [\"sex\",\"year_of_birth\",\"AC\",\"batch\"]\n",
    "AC_VALS = ['AC_stockport_pilot','AC_manchester','AC_oxford','AC_cardiff','AC_glasgow','AC_edinburgh','AC_stoke','AC_reading','AC_bury','AC_newcastle','AC_bristol','AC_barts','AC_nottingham','AC_sheffield','AC_liverpool','AC_middlesborough','AC_hounslow','AC_croydon','AC_birmingham','AC_swansea','AC_wrexham','AC_cheadle_revisit','AC_cheadle_imaging','AC_reading_imaging','AC_newcastle_imaging']\n",
    "BATCH_VALS = ['batch_Batch_b001','batch_Batch_b002','batch_Batch_b003','batch_Batch_b004','batch_Batch_b005','batch_Batch_b006','batch_Batch_b007','batch_Batch_b008','batch_Batch_b009','batch_Batch_b010','batch_Batch_b011','batch_Batch_b012','batch_Batch_b013','batch_Batch_b014','batch_Batch_b015','batch_Batch_b016','batch_Batch_b017','batch_Batch_b018','batch_Batch_b019','batch_Batch_b020','batch_Batch_b021','batch_Batch_b022','batch_Batch_b023','batch_Batch_b024','batch_Batch_b025','batch_Batch_b026','batch_Batch_b027','batch_Batch_b028','batch_Batch_b029','batch_Batch_b030','batch_Batch_b031','batch_Batch_b032','batch_Batch_b033','batch_Batch_b034','batch_Batch_b035','batch_Batch_b036','batch_Batch_b037','batch_Batch_b038','batch_Batch_b039','batch_Batch_b040','batch_Batch_b041','batch_Batch_b042','batch_Batch_b043','batch_Batch_b044','batch_Batch_b045','batch_Batch_b046','batch_Batch_b047','batch_Batch_b048','batch_Batch_b049','batch_Batch_b050','batch_Batch_b051','batch_Batch_b052','batch_Batch_b053','batch_Batch_b054','batch_Batch_b055','batch_Batch_b056','batch_Batch_b057','batch_Batch_b058','batch_Batch_b059','batch_Batch_b060','batch_Batch_b061','batch_Batch_b062','batch_Batch_b063','batch_Batch_b064','batch_Batch_b065','batch_Batch_b066','batch_Batch_b067','batch_Batch_b068','batch_Batch_b069','batch_Batch_b070','batch_Batch_b071','batch_Batch_b072','batch_Batch_b073','batch_Batch_b074','batch_Batch_b075','batch_Batch_b076','batch_Batch_b077','batch_Batch_b078','batch_Batch_b079','batch_Batch_b080','batch_Batch_b081','batch_Batch_b082','batch_Batch_b083','batch_Batch_b084','batch_Batch_b085','batch_Batch_b086','batch_Batch_b087','batch_Batch_b088','batch_Batch_b089','batch_Batch_b090','batch_Batch_b091','batch_Batch_b092','batch_Batch_b093','batch_Batch_b094','batch_Batch_b095','batch_UKBiLEVEAX_b1','batch_UKBiLEVEAX_b10','batch_UKBiLEVEAX_b11','batch_UKBiLEVEAX_b3','batch_UKBiLEVEAX_b4','batch_UKBiLEVEAX_b5','batch_UKBiLEVEAX_b6','batch_UKBiLEVEAX_b7','batch_UKBiLEVEAX_b8','batch_UKBiLEVEAX_b9']\n",
    "ALL_COVARS = INCLUDED_COVARS[:-2] + AC_VALS + BATCH_VALS\n",
    "NUM_PC = 40\n",
    "for i in range(NUM_PC):\n",
    "    ALL_COVARS.append(f\"PC{i+1}\")\n",
    "\n",
    "\n",
    "# phenotype generation constants\n",
    "TARGET_VARIANCE = 1\n",
    "DISEASE_PREVELANCE = 0.02\n",
    "PHENOTYPE_DIR_RESULT_PATH = \"/sci/archive/michall/roeizucker/covar_tests_non_coding_HADASSA_PLINK/phenotypes/\"\n",
    "INCLUDE_COVAR = True\n",
    "AC_EFFECT_SCORE = 1\n",
    "BATCH_EFFECT_SCORE = 1\n",
    "\n",
    "CREATE_COVAR_FILES = True # should we save the covar files\n",
    "BINARY_VARIANT = False\n",
    "\n",
    "\n",
    "# do a logistic regression between PC and phenotype, to show that snps \n",
    "# do not effect through population structure\n",
    "SEX_EFFECT = 3\n",
    "YOB_EFFECT = 1\n",
    "PC_EFFECT_MAX = 0.3\n",
    "\n",
    "COVAR_GENETIC_EFFECT_RATIO = 2\n",
    "HERETEBILITY = 0.2\n",
    "COVAR_EFFECT = 0.5\n",
    "\n",
    "\n",
    "HERETABILITY_SCORES = [0,0.1,0.2,0.3,0.5,0.7]\n",
    "COVARIATE_SCORES = [0,0.1,0.2,0.3,0.5,0.7]\n",
    "# TODO change the name and function to heretibility to heretibility\n",
    "# heretibility is the variance of the genetics / (var genetcis + var covar)\n",
    "\n",
    "AC_EFFECT = [AC_EFFECT_SCORE]*len(AC_VALS)\n",
    "BATCH_EFFECT = [BATCH_EFFECT_SCORE]*len(BATCH_VALS)\n",
    "# add PC stratagy\n",
    "PC_EFFECT = list(np.arange(PC_EFFECT_MAX,0,-PC_EFFECT_MAX/NUM_PC))\n",
    "COVAR_EFFECTS = [SEX_EFFECT,YOB_EFFECT] + AC_EFFECT + BATCH_EFFECT + PC_EFFECT\n",
    "\n",
    "# TODO: change to work as beta.\n",
    "# create a function that accepts a vector of Betas and a flag if its binary/continues and add an option for covariates\n",
    "# If its binary, add prevelance considiration\n",
    "# for a person J the score for J is the sum over all betas of SNPS * the number of alleles. \n",
    "# add a noise so that the variance of phenotype will be 1 (adding noise using 1-sigma) call this Yj\n",
    "# to do so calculate overall variance after simulation, and add a noise with 1- the variance (make sure that the genetic + covar variance is below 1)\n",
    "# in continues state, use Yj as phenotype (maybe mul by a constant)\n",
    "# in binary state the same, need to do a logit (sigmuid and then threashold or just threshold) transformation. detarmine the threshold so that X% of the population are sick\n",
    "# another way, in the binary state instead of noise can do a bernuli on the result of the sigmuid (a value between 0 and 1)\n",
    "# the covariats can be treated the same way the betas are used\n",
    "# read about genetic architucture, compare covariates and betas effect.\n",
    "# the aggregative effect of snps should be larger, but the effect of a single snp should be smaller.\n",
    "\n",
    "# look at GWAS catalog, use a table from there for a specific disease and take their betas (find out how to calculate beta from OR)\n",
    "\n",
    "# variant parameter\n",
    "NUMBER_OF_MAJOR_VARIANTS = 30\n",
    "NUMBER_OF_MEDIUM_VARIANTS = 80\n",
    "NUMBER_OF_LESSER_VARIANTS = 120\n",
    "\n",
    "MAJOR_VARIANT_EFFECT = 0.05\n",
    "MEDIUM_VARIANT_EFFECT = 0.015\n",
    "LESSER_VARIANT_EFFECT = 0.005\n",
    "\n",
    "# change to betas\n",
    "MAJOR_VARIANT_DELTA = 1\n",
    "MEDIUM_VARIANT_DELTA = 0.3\n",
    "LESSER_VARIANT_DELTA = 0.01\n",
    "\n",
    "\n",
    "# TODO: implement memory and threads in script\n",
    "MEMORY = 10000\n",
    "THREADS = 10\n",
    "\n",
    "COVAR_GROUPS = [\n",
    "    \"covariates_year_of_birth_0_PC\",\n",
    "    \"covariates_sex_0_PC\",\n",
    "    \"covariates_sex_year_of_birth_0_PC\",\n",
    "    \"covariates_5_PC\",\n",
    "    \"covariates_sex_year_of_birth_40_PC\",\n",
    "    \"covariates_sex_year_of_birth_batch_40_PC\",\n",
    "    \"covariates_sex_year_of_birth_AC_40_PC\",\n",
    "    \"covariates_sex_year_of_birth_AC_batch_40_PC\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13fe45e6-b4a9-4475-b971-8c7bef13619e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# G = pdp.read_plink1_bin(os.path.join(GENETICS_PATH,TEST_CHROM) + \".bed\",os.path.join(GENETICS_PATH,TEST_CHROM) + \".bim\",os.path.join(GENETICS_PATH,TEST_CHROM) + \".fam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77933a97-9c79-4c35-8e55-326be0341786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# G_values = []\n",
    "# for i in range(1,23):\n",
    "#     chrom = f\"{CHROM_PREFIX}{i}{CHROM_SUFFIX}\"\n",
    "#     print(i)\n",
    "#     G = pdp.read_plink1_bin(os.path.join(GENETICS_PATH,chrom) + \".bed\",\n",
    "#                             os.path.join(GENETICS_PATH,chrom) + \".bim\",\n",
    "#                             os.path.join(GENETICS_PATH,chrom) + \".fam\")\n",
    "#     G_values.append(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c476d1-cd16-4b2c-bc2b-fe6bb27cb586",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_df = pd.read_csv(os.path.join(COVARS_PATH,TEST_COVAR),sep=\"\\t\",header=None)\n",
    "covar_df = covar_df.set_axis([\"iid\",\"fid\"] + ALL_COVARS, axis=1)\n",
    "legal_iid = set(covar_df[\"iid\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb085a4f-b9f0-408f-a139-df4556062188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8a5d4-6e5a-4e54-a517-f099fba75e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd49378-b974-4f2d-8568-3bcfc1280e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes = []\n",
    "# all_variants = []\n",
    "# k = (NUMBER_OF_MAJOR_VARIANTS + NUMBER_OF_MEDIUM_VARIANTS + NUMBER_OF_LESSER_VARIANTS) * 2\n",
    "# for G_val in G_values:\n",
    "#     sizes.append(G_val.shape[1])\n",
    "# sizes_sum = sum(sizes)\n",
    "# for i in range(len(G_values)):\n",
    "#     to_select = int(k * sizes[i] /sizes_sum)\n",
    "#     rng = np.random.default_rng()\n",
    "#     selected_indices = rng.choice(sizes[i], size=to_select, replace=False)\n",
    "#     G_subset = G_values[i].isel(variant=selected_indices)\n",
    "#     G_subset = G_subset.sel(sample=list(legal_iid.intersection(set(G_subset.sample.values))))\n",
    "#     G_values[i] = G_subset\n",
    "#     print(i,G_subset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b66fcf83-2ec3-4789-8670-ebd89b7fb27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:32<00:00, 30.71s/it]\n"
     ]
    }
   ],
   "source": [
    "# G_combined = xr.concat(G_values, dim=\"variant\")\n",
    "G_combined = pdp.read_plink1_bin(os.path.join(GENETICS_PATH,TEST_CHROM) + \".bed\",\n",
    "                            os.path.join(GENETICS_PATH,TEST_CHROM) + \".bim\",\n",
    "                            os.path.join(GENETICS_PATH,TEST_CHROM) + \".fam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80e8f571-0e7f-4ff8-8b37-3a8a792bca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=12345)\n",
    "k = (NUMBER_OF_MAJOR_VARIANTS + NUMBER_OF_MEDIUM_VARIANTS + NUMBER_OF_LESSER_VARIANTS) + 100\n",
    "selected_indices = rng.choice(G_combined.shape[1], size=k, replace=False)\n",
    "G_filtered = G_combined.isel(variant=selected_indices)\n",
    "G_filtered = G_filtered.sel(sample=list(legal_iid.intersection(set(G_filtered.sample.values))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c41704-be76-41f0-818a-d3cbe8ec5931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcdbb11-ddc1-4e9e-94d4-d4fc3b43c224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48a619-6e14-469b-8ac4-3a5f89d3a114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feced8b8-0100-4043-866a-cf54be84e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dataframes = []\n",
    "# counter = 0\n",
    "# for G_val in G_values:\n",
    "#     print(counter)\n",
    "#     counter+=1\n",
    "#     df = G_val.to_dataframe().reset_index()\n",
    "#     dataframes.append(G_val.to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe83dc-76f8-4b18-b117-58e9ca781049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select variants\n",
    "# num_samples, num_variants = G.shape\n",
    "# k = NUMBER_OF_MAJOR_VARIANTS + NUMBER_OF_MEDIUM_VARIANTS + NUMBER_OF_LESSER_VARIANTS + 100\n",
    "# rng = np.random.default_rng(seed=12345)\n",
    "# selected_indices = rng.choice(num_variants, size=k, replace=False)\n",
    "# print(num_samples)\n",
    "# G_subset = G.isel(variant=selected_indices)\n",
    "# G = G_subset\n",
    "# print(G_subset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9c903-a746-49ee-8dcf-d997d9937903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variant_ids = G_subset.coords[\"snp\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43197c6f-198e-4a08-bf68-c6e30ba544ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = G.to_dataframe()\n",
    "# df = df.reset_index()\n",
    "# covar_df = pd.read_csv(os.path.join(COVARS_PATH,TEST_COVAR),sep=\"\\t\",header=None)\n",
    "# covar_df = covar_df.set_axis([\"iid\",\"fid\"] + ALL_COVARS, axis=1)\n",
    "# legal_iid = set(covar_df[\"iid\"].astype(str))\n",
    "# df = df[df[\"iid\"].isin(legal_iid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8d3ea-bfb8-4a63-b28e-dd83d8cdcf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc5213db-24b9-463b-b47e-e93e12d83bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_variants(variants):\n",
    "    unique_variants = variants[:]\n",
    "    random.shuffle(variants)\n",
    "    return unique_variants\n",
    "\n",
    "def get_variant_groups(unique_variants):\n",
    "    major_variants = set(unique_variants[0:NUMBER_OF_MAJOR_VARIANTS])\n",
    "    medium_variants = set(unique_variants[NUMBER_OF_MAJOR_VARIANTS:NUMBER_OF_MAJOR_VARIANTS+NUMBER_OF_MEDIUM_VARIANTS])\n",
    "    lesser_variants = set(unique_variants[NUMBER_OF_MAJOR_VARIANTS+NUMBER_OF_MEDIUM_VARIANTS:NUMBER_OF_MAJOR_VARIANTS+NUMBER_OF_MEDIUM_VARIANTS+NUMBER_OF_LESSER_VARIANTS])\n",
    "    return major_variants, medium_variants, lesser_variants\n",
    "\n",
    "def create_effect_dict(included_variants,major_variants,medium_variants,lesser_variants):\n",
    "    effect_dict = {}\n",
    "    for var in included_variants:\n",
    "        if var in major_variants:\n",
    "            effect_dict[var] = MAJOR_VARIANT_DELTA\n",
    "            continue\n",
    "        if var in medium_variants:\n",
    "            effect_dict[var] = MEDIUM_VARIANT_DELTA\n",
    "            continue\n",
    "        effect_dict[var] = LESSER_VARIANT_DELTA\n",
    "    return effect_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a4fac86-54f1-47c1-9186-af713fdb9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_list = G_filtered.sample.to_series()\n",
    "snp_list = list(G_filtered.snp.to_series())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05d3e911-6df8-4cd0-a9c4-99bca06477b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(snp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd8c7aae-908e-4271-ac90-07b68a7f0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# samples_list = G_combined.sample.to_series()\n",
    "# G_subset = G.sel(sample=test_ids)\n",
    "# sample_df = G_subset.to_dataframe()\n",
    "\n",
    "\n",
    "# sample_df = sample_df.reset_index()\n",
    "# sample_df = sample_df[sample_df[\"iid\"].isin(legal_iid)]\n",
    "# print(sample_df)\n",
    "unique_variants = get_unique_variants(snp_list)\n",
    "major_variants, medium_variants, lesser_variants = get_variant_groups(unique_variants)\n",
    "included_variants = major_variants.union(medium_variants).union(lesser_variants)\n",
    "covar_df['year_of_birth'] = (covar_df['year_of_birth'] - covar_df['year_of_birth'].mean()) / covar_df['year_of_birth'].std()\n",
    "effect_dict = create_effect_dict(included_variants,major_variants,medium_variants,lesser_variants)\n",
    "covar_df[\"covar_effects_chance\"] = None\n",
    "covar_df[\"genetic_chance\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68cc30c-a5bc-4cdb-9e32-b08b0ca1e981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dbc381-22d1-4f0c-a0bc-5b38d1afdcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dddedbd-5302-4ed4-a4cc-05360105e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variant_specific_df(G_subset):\n",
    "    df = G_subset.to_dataframe()\n",
    "    df = df.reset_index()\n",
    "    df = df[df[\"snp\"].isin(included_variants)]\n",
    "    return df\n",
    "\n",
    "def get_genotype_dict(df):\n",
    "    genotype_dict = df[[\"iid\",\"snp\",\"genotype\"]].set_index([\"iid\",\"snp\"]).to_dict(orient=\"index\")\n",
    "    for key in genotype_dict.keys():\n",
    "        genotype_dict[key] = genotype_dict[key][\"genotype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c85cc620-7b2e-46d8-bab7-37605602779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330000 99 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(samples_list),PERSON_BATCH_SIZE):\n",
    "    if i % 6000 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(i,int( 100*(i /len(samples_list))),\"%\")\n",
    "\n",
    "    start = i\n",
    "    end = i+PERSON_BATCH_SIZE\n",
    "    test_ids = list(samples_list[start:end])\n",
    "    G_subset = G_filtered.sel(sample=test_ids)\n",
    "    df = get_variant_specific_df(G_subset)\n",
    "    genotype_dict = get_genotype_dict(df)\n",
    "    # calculate effect for each variant for each person TODO: extract to function\n",
    "    df[\"effect\"] = df[\"snp\"].map(effect_dict)\n",
    "    df[\"effect\"] = df[\"effect\"]*df[\"genotype\"]\n",
    "    df = df.reset_index()\n",
    "\n",
    "    covar_df[\"covar_effects_chance\"] = ((np.array(covar_df[covar_df.columns[2:-2]]) @ (np.array(COVAR_EFFECTS)))) \n",
    "    \n",
    "    # TODO: change name\n",
    "    disease_chance_dict = (1 - df.groupby(\"iid\")[\"effect\"].sum()).to_dict()\n",
    "    # disease_chance_dict\n",
    "    # TODO: change name, this is not a chance, but a result\n",
    "    covar_df[\"genetic_chance\"] = covar_df[\"iid\"].astype(str).map(disease_chance_dict).fillna(covar_df[\"genetic_chance\"])\n",
    "    # adjust so genetic effect and covar effect match the requested\n",
    "\n",
    "\n",
    "# afterwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f42d0a8-31dd-413b-97cc-4a5f6964f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_df = covar_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b93a11e6-58be-4d81-a529-76eebfa6a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_df[\"covar_effects_chance\"] = (covar_df[\"covar_effects_chance\"]-covar_df[\"covar_effects_chance\"].mean())/covar_df[\"covar_effects_chance\"].std()\n",
    "covar_df[\"genetic_chance\"] = (covar_df[\"genetic_chance\"]-covar_df[\"genetic_chance\"].mean())/covar_df[\"genetic_chance\"].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e161e25-3b75-426e-9bac-e587f717d884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a64178b-c827-407b-8797-1929c2e9ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_df.to_csv(\"temp_covar_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f310b-6691-414b-bb61-9e38f3ef816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covar_df = covar_df.set_index(\"iid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff63567-5080-4f54-8729-9004d1faa63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288a8f6-1510-42ed-a467-de788b9517a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "469747b7-27c9-461f-aa86-448058e94a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC effect 6.149999999999994\n",
      "other covars effect 6\n",
      "PC relative effect in PC 0.5061728395061725\n"
     ]
    }
   ],
   "source": [
    "# [SEX_EFFECT,YOB_EFFECT] + AC_EFFECT + BATCH_EFFECT + PC_EFFECT\n",
    "pc_total_effect = sum(PC_EFFECT)\n",
    "other_total_effect = sum([SEX_EFFECT,YOB_EFFECT] +[AC_EFFECT_SCORE,BATCH_EFFECT_SCORE])\n",
    "print(\"PC effect\",pc_total_effect)\n",
    "print(\"other covars effect\",other_total_effect)\n",
    "print(\"PC relative effect in PC\",pc_total_effect / (pc_total_effect+other_total_effect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b757ec70-1c2a-48a8-a00c-7d86e15f64e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted pc relative effect in PC 0.804002242271349\n"
     ]
    }
   ],
   "source": [
    "# ((np.array(covar_df[covar_df.columns[2:-2]]) @ (np.array(COVAR_EFFECTS))))\n",
    "# COVAR_EFFECTS = [SEX_EFFECT,YOB_EFFECT] + AC_EFFECT + BATCH_EFFECT + PC_EFFECT\n",
    "abs_array = np.abs(np.array(covar_df[covar_df.columns[2:-2]]))\n",
    "abs_scores =  abs_array@np.array(COVAR_EFFECTS)\n",
    "covar_only_effects = [0,0] + [0]*(len(AC_EFFECT) + len(BATCH_EFFECT)) + PC_EFFECT\n",
    "covar_only_scores = abs_array@np.array(covar_only_effects)\n",
    "pc_only_scores = covar_only_scores/abs_scores\n",
    "print(\"weighted pc relative effect in PC\",np.mean(pc_only_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d7dbb00-b2c0-454a-8bc5-cbb6e07ca23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print create JSON with parameters\n",
    "parameters_to_save_for_version = {\n",
    "    \"VERSION\":VERSION,\n",
    "    \"TARGET_VARIANCE\":TARGET_VARIANCE,\n",
    "    \"DISEASE_PREVELANCE\":DISEASE_PREVELANCE,\n",
    "    \"NUMBER_OF_MAJOR_VARIANTS\":NUMBER_OF_MAJOR_VARIANTS,\n",
    "    \"NUMBER_OF_MEDIUM_VARIANTS\":NUMBER_OF_MEDIUM_VARIANTS,\n",
    "    \"NUMBER_OF_LESSER_VARIANTS\":NUMBER_OF_LESSER_VARIANTS,\n",
    "    \"MAJOR_VARIANT_DELTA\":MAJOR_VARIANT_DELTA,\n",
    "    \"MEDIUM_VARIANT_DELTA\":MEDIUM_VARIANT_DELTA,\n",
    "    \"LESSER_VARIANT_DELTA\":LESSER_VARIANT_DELTA,\n",
    "    \"BINARY_VARIANT\" : BINARY_VARIANT\n",
    "}\n",
    "if INCLUDE_COVAR:\n",
    "\n",
    "    parameters_to_save_for_version[\"AC_EFFECT_SCORE\"] = AC_EFFECT_SCORE\n",
    "    parameters_to_save_for_version[\"BATCH_EFFECT_SCORE\"] = BATCH_EFFECT_SCORE\n",
    "    parameters_to_save_for_version[\"SEX_EFFECT\"] = SEX_EFFECT\n",
    "    parameters_to_save_for_version[\"YOB_EFFECT\"] = YOB_EFFECT\n",
    "    parameters_to_save_for_version[\"PC_EFFECT_MAX\"] = PC_EFFECT_MAX\n",
    "json_file_name = VERSION + \"_parameters\" + \".json\"\n",
    "if os.path.exists(json_file_name):\n",
    "    raise Exception(\"Version file exists\")\n",
    "with open(json_file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump(parameters_to_save_for_version, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87228e90-0955-4362-abb5-78e9f110f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0.1\n",
      "0 0.2\n",
      "0 0.3\n",
      "0 0.5\n",
      "0 0.7\n",
      "0.1 0\n",
      "0.1 0.1\n",
      "0.1 0.2\n",
      "0.1 0.3\n",
      "0.1 0.5\n",
      "0.1 0.7\n",
      "0.2 0\n",
      "0.2 0.1\n",
      "0.2 0.2\n",
      "0.2 0.3\n",
      "0.2 0.5\n",
      "0.2 0.7\n",
      "0.3 0\n",
      "0.3 0.1\n",
      "0.3 0.2\n",
      "0.3 0.3\n",
      "0.3 0.5\n",
      "0.3 0.7\n",
      "0.5 0\n",
      "0.5 0.1\n",
      "0.5 0.2\n",
      "0.5 0.3\n",
      "0.5 0.5\n",
      "0.5 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3155768/2502292744.py:17: RuntimeWarning: invalid value encountered in scalar power\n",
      "  noise = np.random.normal(mu, sigma**0.5, len(temp_cov_df))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0\n",
      "0.7 0.1\n",
      "0.7 0.2\n",
      "0.7 0.3\n",
      "0.7 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3155768/2502292744.py:17: RuntimeWarning: invalid value encountered in scalar power\n",
      "  noise = np.random.normal(mu, sigma**0.5, len(temp_cov_df))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3155768/2502292744.py:17: RuntimeWarning: invalid value encountered in scalar power\n",
      "  noise = np.random.normal(mu, sigma**0.5, len(temp_cov_df))\n"
     ]
    }
   ],
   "source": [
    "# TODO: add creation of multiple phenotype files\n",
    "covar_dfs = []\n",
    "for her_score in HERETABILITY_SCORES:\n",
    "    for cov_score in COVARIATE_SCORES:\n",
    "        print(her_score,cov_score)\n",
    "        temp_cov_df = covar_df.copy()\n",
    "        gene_var = ((temp_cov_df[\"genetic_chance\"]).var())\n",
    "        covar_var = (temp_cov_df[\"covar_effects_chance\"].var())\n",
    "        genetic_factor = np.sqrt(her_score/gene_var)\n",
    "        covar_factor = np.sqrt(cov_score/covar_var)\n",
    "        temp_cov_df[\"genetic_chance\"] = temp_cov_df[\"genetic_chance\"] * genetic_factor\n",
    "        temp_cov_df[\"covar_effects_chance\"] = temp_cov_df[\"covar_effects_chance\"] * covar_factor\n",
    "        temp_cov_df[\"disease_chance\"] = temp_cov_df[\"genetic_chance\"] + temp_cov_df[\"covar_effects_chance\"]\n",
    "        added_variance = TARGET_VARIANCE -temp_cov_df[\"disease_chance\"].var()\n",
    "        # input(added_variance)\n",
    "        mu, sigma = 0, added_variance # mean and standard deviation\n",
    "        noise = np.random.normal(mu, sigma**0.5, len(temp_cov_df))\n",
    "        temp_cov_df[\"disease_chance\"] = temp_cov_df[\"disease_chance\"] + noise\n",
    "        # temp_cov_df[\"disease_chance\"].var()\n",
    "        quantile = (temp_cov_df[[\"disease_chance\"]].quantile(1 - DISEASE_PREVELANCE, method=\"table\", interpolation=\"nearest\")[\"disease_chance\"])\n",
    "        if BINARY_VARIANT:\n",
    "            temp_cov_df['disease_indicator'] = (\n",
    "                temp_cov_df['disease_chance'] > quantile\n",
    "            ).astype(int).astype(float)\n",
    "        else:\n",
    "            temp_cov_df['disease_indicator'] = temp_cov_df['disease_chance']\n",
    "        # temp_cov_df.dropna()\n",
    "        covar_dfs.append([temp_cov_df,her_score,cov_score])\n",
    "        if CREATE_COVAR_FILES:\n",
    "            temp_cov_df.to_csv(f\"{COVAR_DF_PREFIX}_v={VERSION}_her={her_score}_cov={cov_score}.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e9d40-9ae8-4adf-8948-e5c80db4cdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92cca73c-c1a2-4589-96c8-63f48d955229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0018202619673667745\n",
      "her_score 0\n",
      "cov_score 0.1\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(covar_dfs[i][0][\"disease_indicator\"].dropna().mean())\n",
    "print(\"her_score\",covar_dfs[i][1])\n",
    "print(\"cov_score\",covar_dfs[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3d5e3a4-a31e-4fa3-b24c-1983458272b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>fid</th>\n",
       "      <th>sex</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>AC_stockport_pilot</th>\n",
       "      <th>AC_manchester</th>\n",
       "      <th>AC_oxford</th>\n",
       "      <th>AC_cardiff</th>\n",
       "      <th>AC_glasgow</th>\n",
       "      <th>AC_edinburgh</th>\n",
       "      <th>...</th>\n",
       "      <th>PC35</th>\n",
       "      <th>PC36</th>\n",
       "      <th>PC37</th>\n",
       "      <th>PC38</th>\n",
       "      <th>PC39</th>\n",
       "      <th>PC40</th>\n",
       "      <th>covar_effects_chance</th>\n",
       "      <th>genetic_chance</th>\n",
       "      <th>disease_chance</th>\n",
       "      <th>disease_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5895328</td>\n",
       "      <td>5895328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.152223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419695</td>\n",
       "      <td>-1.412190</td>\n",
       "      <td>5.011600</td>\n",
       "      <td>-2.041770</td>\n",
       "      <td>-0.329472</td>\n",
       "      <td>-0.610231</td>\n",
       "      <td>-0.459752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.360605</td>\n",
       "      <td>-1.360605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5764375</td>\n",
       "      <td>5764375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.076080</td>\n",
       "      <td>0.282474</td>\n",
       "      <td>1.712010</td>\n",
       "      <td>-1.723410</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>1.834630</td>\n",
       "      <td>-0.202652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259322</td>\n",
       "      <td>0.259322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5503073</td>\n",
       "      <td>5503073</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.901703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.917620</td>\n",
       "      <td>3.797780</td>\n",
       "      <td>-0.783315</td>\n",
       "      <td>-1.714340</td>\n",
       "      <td>4.746740</td>\n",
       "      <td>-0.425447</td>\n",
       "      <td>0.351544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007729</td>\n",
       "      <td>-0.007729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2563626</td>\n",
       "      <td>2563626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.150145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180031</td>\n",
       "      <td>0.908227</td>\n",
       "      <td>-1.488970</td>\n",
       "      <td>-2.507100</td>\n",
       "      <td>-2.025750</td>\n",
       "      <td>7.023560</td>\n",
       "      <td>-0.114147</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.610841</td>\n",
       "      <td>-1.610841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4980832</td>\n",
       "      <td>4980832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.400665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000040</td>\n",
       "      <td>1.880090</td>\n",
       "      <td>0.433608</td>\n",
       "      <td>-2.291620</td>\n",
       "      <td>-2.461820</td>\n",
       "      <td>-3.445180</td>\n",
       "      <td>0.153879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240332</td>\n",
       "      <td>0.240332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333366</th>\n",
       "      <td>2243883</td>\n",
       "      <td>2243883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.275405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.756630</td>\n",
       "      <td>-5.489920</td>\n",
       "      <td>2.986760</td>\n",
       "      <td>-0.533189</td>\n",
       "      <td>-0.582788</td>\n",
       "      <td>0.070181</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963406</td>\n",
       "      <td>0.963406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333367</th>\n",
       "      <td>3570729</td>\n",
       "      <td>3570729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.476153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.785830</td>\n",
       "      <td>1.074660</td>\n",
       "      <td>-2.581080</td>\n",
       "      <td>-0.671792</td>\n",
       "      <td>2.334690</td>\n",
       "      <td>-3.509470</td>\n",
       "      <td>0.393571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.649838</td>\n",
       "      <td>-0.649838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333368</th>\n",
       "      <td>1663456</td>\n",
       "      <td>1663456</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.277482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.008020</td>\n",
       "      <td>-1.370330</td>\n",
       "      <td>-3.174280</td>\n",
       "      <td>-3.719140</td>\n",
       "      <td>-1.817060</td>\n",
       "      <td>0.452773</td>\n",
       "      <td>0.212045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182012</td>\n",
       "      <td>0.182012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333369</th>\n",
       "      <td>3118989</td>\n",
       "      <td>3118989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.152223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.979120</td>\n",
       "      <td>4.153130</td>\n",
       "      <td>-5.280610</td>\n",
       "      <td>-2.201190</td>\n",
       "      <td>-0.167185</td>\n",
       "      <td>-0.494174</td>\n",
       "      <td>0.102179</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.638484</td>\n",
       "      <td>0.638484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333370</th>\n",
       "      <td>4573284</td>\n",
       "      <td>4573284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.150145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343660</td>\n",
       "      <td>3.394630</td>\n",
       "      <td>-3.394460</td>\n",
       "      <td>1.916540</td>\n",
       "      <td>-1.548800</td>\n",
       "      <td>-3.454470</td>\n",
       "      <td>0.170340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877406</td>\n",
       "      <td>0.877406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332645 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            iid      fid  sex  year_of_birth  AC_stockport_pilot  \\\n",
       "0       5895328  5895328  1.0      -1.152223                 0.0   \n",
       "1       5764375  5764375  0.0      -0.024885                 0.0   \n",
       "2       5503073  5503073  1.0      -0.901703                 0.0   \n",
       "3       2563626  2563626  1.0      -0.150145                 0.0   \n",
       "4       4980832  4980832  1.0      -0.400665                 0.0   \n",
       "...         ...      ...  ...            ...                 ...   \n",
       "333366  2243883  2243883  1.0      -0.275405                 0.0   \n",
       "333367  3570729  3570729  1.0       0.476153                 0.0   \n",
       "333368  1663456  1663456  1.0      -1.277482                 0.0   \n",
       "333369  3118989  3118989  0.0      -1.152223                 0.0   \n",
       "333370  4573284  4573284  0.0      -0.150145                 0.0   \n",
       "\n",
       "        AC_manchester  AC_oxford  AC_cardiff  AC_glasgow  AC_edinburgh  ...  \\\n",
       "0                 0.0        1.0         0.0         0.0           0.0  ...   \n",
       "1                 0.0        1.0         0.0         0.0           0.0  ...   \n",
       "2                 0.0        0.0         1.0         0.0           0.0  ...   \n",
       "3                 0.0        0.0         0.0         0.0           0.0  ...   \n",
       "4                 0.0        0.0         0.0         0.0           0.0  ...   \n",
       "...               ...        ...         ...         ...           ...  ...   \n",
       "333366            1.0        0.0         0.0         0.0           0.0  ...   \n",
       "333367            0.0        0.0         0.0         0.0           0.0  ...   \n",
       "333368            0.0        0.0         0.0         0.0           0.0  ...   \n",
       "333369            0.0        0.0         0.0         0.0           0.0  ...   \n",
       "333370            0.0        0.0         0.0         0.0           0.0  ...   \n",
       "\n",
       "            PC35      PC36      PC37      PC38      PC39      PC40  \\\n",
       "0      -0.419695 -1.412190  5.011600 -2.041770 -0.329472 -0.610231   \n",
       "1      -3.076080  0.282474  1.712010 -1.723410 -0.140920  1.834630   \n",
       "2       6.917620  3.797780 -0.783315 -1.714340  4.746740 -0.425447   \n",
       "3       0.180031  0.908227 -1.488970 -2.507100 -2.025750  7.023560   \n",
       "4       3.000040  1.880090  0.433608 -2.291620 -2.461820 -3.445180   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "333366 -1.756630 -5.489920  2.986760 -0.533189 -0.582788  0.070181   \n",
       "333367 -1.785830  1.074660 -2.581080 -0.671792  2.334690 -3.509470   \n",
       "333368 -4.008020 -1.370330 -3.174280 -3.719140 -1.817060  0.452773   \n",
       "333369 -1.979120  4.153130 -5.280610 -2.201190 -0.167185 -0.494174   \n",
       "333370 -0.343660  3.394630 -3.394460  1.916540 -1.548800 -3.454470   \n",
       "\n",
       "        covar_effects_chance  genetic_chance  disease_chance  \\\n",
       "0                  -0.459752             0.0       -1.360605   \n",
       "1                  -0.202652             0.0        0.259322   \n",
       "2                   0.351544             0.0       -0.007729   \n",
       "3                  -0.114147            -0.0       -1.610841   \n",
       "4                   0.153879             0.0        0.240332   \n",
       "...                      ...             ...             ...   \n",
       "333366              0.006754             0.0        0.963406   \n",
       "333367              0.393571             0.0       -0.649838   \n",
       "333368              0.212045             0.0        0.182012   \n",
       "333369              0.102179            -0.0        0.638484   \n",
       "333370              0.170340             0.0        0.877406   \n",
       "\n",
       "        disease_indicator  \n",
       "0               -1.360605  \n",
       "1                0.259322  \n",
       "2               -0.007729  \n",
       "3               -1.610841  \n",
       "4                0.240332  \n",
       "...                   ...  \n",
       "333366           0.963406  \n",
       "333367          -0.649838  \n",
       "333368           0.182012  \n",
       "333369           0.638484  \n",
       "333370           0.877406  \n",
       "\n",
       "[332645 rows x 178 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covar_dfs[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "318d5ecd-cf33-41de-98ff-010c509c64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_dict = {}\n",
    "\n",
    "variant_dict[\"major_vars\"] = list(major_variants)\n",
    "variant_dict[\"med_vars\"] = list(medium_variants)\n",
    "variant_dict[\"lesser_vars\"] = list(lesser_variants)\n",
    "json_file_name = VERSION + \"_variants.json\"\n",
    "with open(json_file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump(variant_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79491a-9fb8-4cb0-98ef-cef649a3fb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "799ac707-c3a8-4818-89c8-540b756c4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = []\n",
    "for temp_cov_df,her_score,cov_score in covar_dfs:\n",
    "    phenotype_file_result_name = (\n",
    "        f\"generated_pehn_result_ver={VERSION}_heretability={her_score}_covar_effect={cov_score}\")\n",
    "    phenotype_file_result_name = phenotype_file_result_name+\".txt\"\n",
    "    phenotype_file_path = os.path.join(PHENOTYPE_DIR_RESULT_PATH,phenotype_file_result_name)\n",
    "    temp_cov_df[[\"iid\",\"fid\",\"disease_indicator\"]].to_csv(phenotype_file_path,index=False,header=False,sep=\"\\t\")\n",
    "\n",
    "    chrom_path = os.path.join(GENETICS_PATH,TEST_CHROM)\n",
    "    result_path = os.path.join(PLINK_RESULT_DIR,phenotype_file_result_name.replace(\".txt\",\"\"))\n",
    "    for covar_type in COVAR_GROUPS:\n",
    "        covar_file = os.path.join(COVARS_PATH,covar_type + \".txt\")\n",
    "        result_path = os.path.join(PLINK_RESULT_DIR,phenotype_file_result_name.replace(\".txt\",covar_type))\n",
    "        command =f\"{PLINK_PATH} --bed {chrom_path}.bed --bim {chrom_path}.bim --fam {chrom_path}.fam --pheno {phenotype_file_path} --covar {covar_file}  --out  {result_path} --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads 10 --memory 10000 --1 --adjust\"\n",
    "        # print(command)\n",
    "        # print(f'sbatch --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"{command}\"')\n",
    "        commands.append(f'sbatch --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"{command}\"')\n",
    "    command =f\"{PLINK_PATH} --bed {chrom_path}.bed --bim {chrom_path}.bim --fam {chrom_path}.fam --pheno {phenotype_file_path} --out  {result_path} --glm hide-covar --mac 20 --covar-variance-standardize --freq --threads 10 --memory 10000 --1  --adjust\"\n",
    "    # print(command)\n",
    "    result_path = os.path.join(PLINK_RESULT_DIR,phenotype_file_result_name.replace(\".txt\",\"_no_covar\"))\n",
    "    # print(f'sbatch --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"{command}\"')\n",
    "    commands.append(f'sbatch --mem=12g -c10 --time=3-0 --requeue --killable --wrap=\"{command}\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "613b98dc-8627-4a8e-8787-53fdc807b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = \"temp_file.sh\"\n",
    "counter = 0\n",
    "with open(temp_file,\"w\") as f:\n",
    "    for com in commands:\n",
    "        f.write(com + \"\\n\")\n",
    "        f.write(\"sleep 2\\n\")\n",
    "        counter+=1\n",
    "        if counter%30 == 0:\n",
    "            f.write(\"sleep 10\\n\")\n",
    "\n",
    "!chmod 744 {temp_file}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc411ac-f24d-4be1-bf22-675aab73f26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3980f-2c5a-4a44-898a-dabe0ba51735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# included_variants = major_variants.union(medium_variants).union(lesser_variants)\n",
    "# # TODO: add protective variants\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34da0a-1eac-4985-b0f8-95fc1d269a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df[\"variant\"].isin(included_variants)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b13cc-4d8f-4178-aebd-794f0817209b",
   "metadata": {},
   "source": [
    "## GWAS simulation visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b478a4e-6009-40a2-ac78-901a9cde73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PVAL_THRESHOLD = 5*10**-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb3e7c72-268b-4715-9be3-798b32575fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_name = VERSION + \"_variants.json\"\n",
    "with open(json_file_name) as json_file:\n",
    "        variant_data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d3cc716-8589-46bf-938b-8aa8e29221da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_dict = sample_df[[\"variant\",\"snp\"]].set_index(\"variant\").to_dict()[\"snp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2653f75-a815-48dd-8d67-5e86ed16eeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0374ac18-2749-46f7-b58f-5023e15e722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in variant_data:\n",
    "#     for i in range(len(variant_data[key])):\n",
    "#         variant_data[key][i] = var_dict[variant_data[key][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622550d-ce4d-419b-a325-cbf8f504eb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f54b753-3ba0-460f-a49a-8439e14bf43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for her_score in HERETABILITY_SCORES:\n",
    "    for cov_score in COVARIATE_SCORES:\n",
    "        if her_score + cov_score > 1:\n",
    "            continue\n",
    "        for covar_type in COVAR_GROUPS:\n",
    "            try:\n",
    "                phenotype_file_result_name = (\n",
    "                    f\"generated_pehn_result_ver={VERSION}_heretability={her_score}_covar_effect={cov_score}\")\n",
    "                phenotype_file_result_name = phenotype_file_result_name+\".txt\"\n",
    "                result_path = os.path.join(PLINK_RESULT_DIR,phenotype_file_result_name.replace(\".txt\",covar_type))\n",
    "                covar_file = os.path.join(COVARS_PATH,covar_type + \".txt\")\n",
    "                result_path = os.path.join(PLINK_RESULT_DIR,phenotype_file_result_name.replace(\".txt\",covar_type) + F\".{FILE_ENDING}\")\n",
    "                df = pd.read_csv(result_path,sep=\"\\t\")\n",
    "                df = df[df[\"P\"] < PVAL_THRESHOLD]\n",
    "                variants = set(df[\"ID\"])\n",
    "                found_major = variants.intersection( variant_data[\"major_vars\"])\n",
    "                found_medium = variants.intersection( variant_data[\"med_vars\"])\n",
    "                found_lesser = variants.intersection( variant_data[\"lesser_vars\"])\n",
    "                if VERBOSE:\n",
    "                    print(covar_type,her_score,cov_score)\n",
    "                    print(\"found_major\",len(found_major),\"/\",len(variant_data[\"major_vars\"]))\n",
    "                    print(\"found_medium\",len(found_medium),\"/\",len(variant_data[\"med_vars\"]))\n",
    "                    print(\"found_lesser\",len(found_lesser),\"/\",len(variant_data[\"lesser_vars\"]))\n",
    "                    print(\"found_overall\", len(variants))\n",
    "                    print(\"found_extra\",len(variants - found_major.union(found_medium).union(found_lesser)))\n",
    "                results.append(\n",
    "                    [her_score,cov_score,covar_type,len(found_major),len(found_medium),\n",
    "                     len(found_lesser),len(variants),len(variants - found_major.union(found_medium).union(found_lesser))])\n",
    "                # print(variants)\n",
    "            except OSError as exc:\n",
    "                print(exc)\n",
    "                print(covar_file,\"failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41abc003-fdd0-4cef-91df-db7ee4851ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"her_score\",\"cov_score\",\"covar_type\",\"found_major\",\"found_medium\",\"found_lesser\",\"found_overall\",\"found_extra\"]\n",
    "res_df = pd.DataFrame(results,columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c34aad02-40b5-4540-81c6-a13498a00783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 9.0\n",
      "0 0.1 41.125\n",
      "0 0.2 75.0\n",
      "0 0.3 103.75\n",
      "0 0.5 149.625\n",
      "0 0.7 184.625\n",
      "0.1 0 11.0\n",
      "0.1 0.1 42.25\n",
      "0.1 0.2 70.125\n",
      "0.1 0.3 96.75\n",
      "0.1 0.5 135.25\n",
      "0.1 0.7 184.25\n",
      "0.2 0 19.875\n",
      "0.2 0.1 41.75\n",
      "0.2 0.2 75.0\n",
      "0.2 0.3 100.25\n",
      "0.2 0.5 148.75\n",
      "0.2 0.7 180.25\n",
      "0.3 0 9.75\n",
      "0.3 0.1 39.5\n",
      "0.3 0.2 80.5\n",
      "0.3 0.3 104.875\n",
      "0.3 0.5 147.0\n",
      "0.3 0.7 187.5\n",
      "0.5 0 16.25\n",
      "0.5 0.1 42.25\n",
      "0.5 0.2 75.0\n",
      "0.5 0.3 94.25\n",
      "0.5 0.5 154.0\n",
      "0.5 0.7 nan\n",
      "0.7 0 15.5\n",
      "0.7 0.1 44.25\n",
      "0.7 0.2 74.75\n",
      "0.7 0.3 101.25\n",
      "0.7 0.5 nan\n",
      "0.7 0.7 nan\n"
     ]
    }
   ],
   "source": [
    "# for her_score in HERETABILITY_SCORES:\n",
    "#     for cov_score in COVARIATE_SCORES:\n",
    "#         print(her_score,cov_score,res_df[(res_df[\"her_score\"] == her_score)\n",
    "#               & (res_df[\"cov_score\"] == cov_score)][\"found_extra\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487bfee-be72-484d-9f25-d0cf1901b808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
